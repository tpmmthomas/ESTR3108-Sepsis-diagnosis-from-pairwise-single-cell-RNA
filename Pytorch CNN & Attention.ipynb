{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# for reading and displaying images\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Transformers\n",
    "from module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data set (small amount to test if it works first)\n",
    "\n",
    "xtrain = r\"data/training_sample_NoSparse.csv.gz\"\n",
    "ytrain = r\"data/training_label_NoSparse.csv.gz\"\n",
    "xtest = r\"data/testing_sample_NoSparse.csv.gz\"\n",
    "ytest = r\"data/testing_label_NoSparse.csv.gz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15161, 14094)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check balance\n",
    "samplesdf = pd.DataFrame()\n",
    "for df in  pd.read_csv(ytrain,compression =\"gzip\",delimiter=',', chunksize = 10000, header=0):\n",
    "    samplesdf = samplesdf.append(df)\n",
    "y_train = samplesdf.to_numpy()\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for x in y_train:\n",
    "    if x == 0:\n",
    "        num0 = num0 + 1\n",
    "    else:\n",
    "        num1 = num1 + 1\n",
    "num0,num1 #checking if it is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.   ... 3.11 0.   3.69]\n",
      " [0.   0.   0.   ... 3.16 0.   3.33]\n",
      " [0.   0.   0.   ... 2.98 0.   3.64]\n",
      " ...\n",
      " [1.39 0.   0.   ... 1.95 0.   3.57]\n",
      " [0.   2.08 0.   ... 2.71 0.   3.09]\n",
      " [0.   0.   0.   ... 3.12 0.   2.85]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(xtrain,compression =\"gzip\",delimiter=',', nrows=123, header=0)\n",
    "x_train = df.to_numpy()\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self,samples,labels,numrows):\n",
    "\n",
    "        self.data = pd.read_csv(samples,compression =\"gzip\",delimiter=',', nrows = numrows, header=0)\n",
    "        self.label = pd.read_csv(labels,compression =\"gzip\",delimiter=',', nrows = numrows, header=0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        rna = self.data.iloc[idx]\n",
    "        seplb = self.label.iloc[idx]\n",
    "        rna = np.array([rna])\n",
    "        seplb = np.array([seplb])\n",
    "        rna = rna.astype('double').reshape(-1,3273)\n",
    "        i = 0\n",
    "        d = np.zeros((len(seplb),2))\n",
    "        for x in seplb:\n",
    "            if x == 0:\n",
    "                d[i] = [1,0]\n",
    "            else:\n",
    "                d[i] = [0,1]\n",
    "        sample = {'rna': rna, 'label': d}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(samples=xtrain,labels=ytrain,numrows = 29255)\n",
    "test_dataset = Dataset(samples = xtest,labels = ytest,numrows = 3241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 20             # train the training data n times, to save time, we just train 1 epoch\n",
    "LR = 0.0001              # learning rate\n",
    "batch_size = 32\n",
    "wd = LR / EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (x,1, 8949)\n",
    "            nn.Conv1d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=4,            # n_filters\n",
    "                kernel_size=3,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=1,                  # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (x,64,8949)\n",
    "            nn.BatchNorm1d(4),\n",
    "            nn.ReLU(),                      # activation\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (x,64, 8949)\n",
    "            nn.Conv1d(4,4,3,1,1),            \n",
    "            nn.ReLU(),  \n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.MaxPool1d(kernel_size =2, stride=2,ceil_mode = True),                # output shape (x,64,4478)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         # input shape (x,64,4478)\n",
    "            nn.Conv1d(4, 4, 3, 1, 1),     # output shape (x,128,4478)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool1d(kernel_size =2, stride=2,ceil_mode = True),                # output shape (x,128,2238)\n",
    "        )\n",
    "        self.out = nn.Linear(3276 , 2)   # fully connected layer, output 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cnn = CNN()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "if torch.cuda.is_available():\n",
    "    cnn = cnn.cuda()\n",
    "    loss_func = loss_func.cuda()\n",
    "cnn = cnn.double()    \n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetTransformer(nn.Module):\n",
    "    def __init__(self, dim_input, num_outputs, dim_output,\n",
    "            num_inds=32, dim_hidden=128, num_heads=2, ln=False):\n",
    "        super(SetTransformer, self).__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "                ISAB(dim_input, dim_hidden, num_heads, num_inds, ln=ln),\n",
    "                ISAB(dim_hidden, dim_hidden, num_heads, num_inds, ln=ln))\n",
    "        self.dec = nn.Sequential(\n",
    "                PMA(dim_hidden, num_heads, num_outputs, ln=ln),\n",
    "                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
    "                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
    "                nn.Linear(dim_hidden, dim_output))\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dec(self.enc(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trans = SetTransformer(3273,2,1)\n",
    "optimizer = torch.optim.Adam(trans.parameters(), lr=LR)   \n",
    "loss_func = nn.L1Loss()                      \n",
    "if torch.cuda.is_available():\n",
    "    loss_func = loss_func.cuda()\n",
    "    trans = trans.cuda()\n",
    "trans = trans.double()\n",
    "print(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Trans(nn.Module):\n",
    "    def __init__(self, dim_input, num_outputs, dim_output,\n",
    "            num_inds=32, dim_hidden=128, num_heads=4, ln=False):\n",
    "        super(CNN_Trans, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (x,1, 8949)\n",
    "            nn.Conv1d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=4,            # n_filters\n",
    "                kernel_size=3,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=1,                  # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (x,64,8949)\n",
    "            nn.BatchNorm1d(4),\n",
    "            nn.ReLU(),                      # activation\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (x,64, 8949)\n",
    "            nn.Conv1d(4,4,3,1,1),            \n",
    "            nn.ReLU(),  \n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.MaxPool1d(kernel_size =2, stride=2,ceil_mode = True),                # output shape (x,64,4478)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         # input shape (x,64,4478)\n",
    "            nn.Conv1d(4, 4, 3, 1, 1),     # output shape (x,128,4478)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool1d(kernel_size =2, stride=2,ceil_mode = True),                # output shape (x,128,2238)\n",
    "        )\n",
    "        self.enc = nn.Sequential(\n",
    "                ISAB(dim_input, dim_hidden, num_heads, num_inds, ln=ln),\n",
    "                ISAB(dim_hidden, dim_hidden, num_heads, num_inds, ln=ln))\n",
    "        self.dec = nn.Sequential(\n",
    "                PMA(dim_hidden, num_heads, num_outputs, ln=ln),\n",
    "                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
    "                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
    "                nn.Linear(dim_hidden, dim_output))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = x.reshape(-1,1,3276)\n",
    "        return self.dec(self.enc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Trans(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(1, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(4, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv1d(4, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (enc): Sequential(\n",
      "    (0): ISAB(\n",
      "      (mab0): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=3276, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=3276, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (mab1): MAB(\n",
      "        (fc_q): Linear(in_features=3276, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ISAB(\n",
      "      (mab0): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (mab1): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec): Sequential(\n",
      "    (0): PMA(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnntrans = CNN_Trans(3276,1,2)\n",
    "optimizer = torch.optim.Adam(cnntrans.parameters(), lr=LR)   \n",
    "loss_func = nn.L1Loss()                      \n",
    "if torch.cuda.is_available():\n",
    "    loss_func = loss_func.cuda()\n",
    "    cnntrans = cnntrans.cuda()\n",
    "cnntrans = cnntrans.double()\n",
    "print(cnntrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallSetTransformer(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "            SAB(dim_in=1, dim_out=64, num_heads=4),\n",
    "            SAB(dim_in=64, dim_out=64, num_heads=4),\n",
    "        )\n",
    "        self.dec = nn.Sequential(\n",
    "            PMA(dim=64, num_heads=4, num_seeds=1),\n",
    "            nn.Linear(in_features=64, out_features=2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        x = self.dec(x)\n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smalltrans = SmallSetTransformer()\n",
    "optimizer = torch.optim.Adam(smalltrans.parameters(), lr=LR)   \n",
    "loss_func = nn.L1Loss()                      \n",
    "if torch.cuda.is_available():\n",
    "    loss_func = loss_func.cuda()\n",
    "    smalltrans = smalltrans.cuda()\n",
    "smalltrans = smalltrans.double()\n",
    "print(smalltrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in train_loader:\n",
    "            rna,labels = batch[\"rna\"], batch[\"label\"] \n",
    "            if torch.cuda.is_available():\n",
    "                rna = rna.cuda()\n",
    "                labels = labels.cuda()\n",
    "            labels = labels.reshape(-1,2)\n",
    "            outputs = model(rna)\n",
    "            outputs = outputs.reshape(-1,2)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, labels = torch.max(labels.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "           # print(total,correct)\n",
    "\n",
    "        print('Train Accuracy of the model on the train rna: {} %'.format((correct / total) * 100))\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in test_loader:\n",
    "            rna,labels = batch[\"rna\"], batch[\"label\"] \n",
    "            if torch.cuda.is_available():\n",
    "                rna = rna.cuda()\n",
    "                labels = labels.cuda()\n",
    "            labels = labels.reshape(-1,2)\n",
    "            outputs = model(rna)\n",
    "            outputs = outputs.reshape(-1,2)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, labels = torch.max(labels.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    #print(total,correct)\n",
    "\n",
    "        print('Test Accuracy of the model on the test rna: {} %'.format((correct / total) * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(model): \n",
    "    total_step = len(train_loader)\n",
    "    num_epoch = EPOCH\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            # Run the forward pass\n",
    "            rna,labels = batch[\"rna\"], batch[\"label\"] \n",
    "            if torch.cuda.is_available():\n",
    "                rna = rna.cuda()\n",
    "                labels = labels.cuda()\n",
    "            outputs = model(rna)\n",
    "            labels = labels.long()\n",
    "            #print(outputs)\n",
    "            outputs = outputs.reshape(-1,2)\n",
    "            labels = labels.reshape(-1,2)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            # Backprop and perform Adam optimisation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track the accuracy\n",
    "            total = labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, labels = torch.max(labels.data, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            train_acc.append(correct / total)\n",
    "            if i % 100 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                        .format(epoch + 1, num_epoch , i + 1, total_step, loss.item(),\n",
    "                                (correct / total) * 100))\n",
    "        test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [1/915], Loss: 0.6362, Accuracy: 40.62%\n",
      "Epoch [1/20], Step [101/915], Loss: 0.4805, Accuracy: 46.88%\n",
      "Epoch [1/20], Step [201/915], Loss: 0.3677, Accuracy: 59.38%\n",
      "Epoch [1/20], Step [301/915], Loss: 0.2071, Accuracy: 81.25%\n",
      "Epoch [1/20], Step [401/915], Loss: 0.2707, Accuracy: 78.12%\n",
      "Epoch [1/20], Step [501/915], Loss: 0.3448, Accuracy: 65.62%\n",
      "Epoch [1/20], Step [601/915], Loss: 0.2409, Accuracy: 75.00%\n",
      "Epoch [1/20], Step [701/915], Loss: 0.3151, Accuracy: 68.75%\n",
      "Epoch [1/20], Step [801/915], Loss: 0.2835, Accuracy: 78.12%\n",
      "Epoch [1/20], Step [901/915], Loss: 0.3373, Accuracy: 65.62%\n",
      "Train Accuracy of the model on the train rna: 65.67766193813024 %\n",
      "Test Accuracy of the model on the test rna: 64.14686825053995 %\n",
      "Epoch [2/20], Step [1/915], Loss: 0.3860, Accuracy: 62.50%\n",
      "Epoch [2/20], Step [101/915], Loss: 0.2878, Accuracy: 78.12%\n",
      "Epoch [2/20], Step [201/915], Loss: 0.2543, Accuracy: 71.88%\n",
      "Epoch [2/20], Step [301/915], Loss: 0.1898, Accuracy: 84.38%\n",
      "Epoch [2/20], Step [401/915], Loss: 0.3664, Accuracy: 62.50%\n",
      "Epoch [2/20], Step [501/915], Loss: 0.2417, Accuracy: 75.00%\n",
      "Epoch [2/20], Step [601/915], Loss: 0.3199, Accuracy: 65.62%\n",
      "Epoch [2/20], Step [701/915], Loss: 0.3039, Accuracy: 71.88%\n",
      "Epoch [2/20], Step [801/915], Loss: 0.2584, Accuracy: 71.88%\n",
      "Epoch [2/20], Step [901/915], Loss: 0.2516, Accuracy: 75.00%\n",
      "Train Accuracy of the model on the train rna: 79.29242864467612 %\n",
      "Test Accuracy of the model on the test rna: 76.9824128355446 %\n",
      "Epoch [3/20], Step [1/915], Loss: 0.1906, Accuracy: 81.25%\n",
      "Epoch [3/20], Step [101/915], Loss: 0.3201, Accuracy: 68.75%\n",
      "Epoch [3/20], Step [201/915], Loss: 0.0701, Accuracy: 93.75%\n",
      "Epoch [3/20], Step [301/915], Loss: 0.2253, Accuracy: 78.12%\n",
      "Epoch [3/20], Step [401/915], Loss: 0.0941, Accuracy: 90.62%\n",
      "Epoch [3/20], Step [501/915], Loss: 0.1269, Accuracy: 87.50%\n",
      "Epoch [3/20], Step [601/915], Loss: 0.1380, Accuracy: 87.50%\n",
      "Epoch [3/20], Step [701/915], Loss: 0.3127, Accuracy: 68.75%\n",
      "Epoch [3/20], Step [801/915], Loss: 0.2219, Accuracy: 78.12%\n",
      "Epoch [3/20], Step [901/915], Loss: 0.2386, Accuracy: 75.00%\n",
      "Train Accuracy of the model on the train rna: 79.33002905486242 %\n",
      "Test Accuracy of the model on the test rna: 76.48873804381364 %\n",
      "Epoch [4/20], Step [1/915], Loss: 0.2426, Accuracy: 78.12%\n",
      "Epoch [4/20], Step [101/915], Loss: 0.2739, Accuracy: 71.88%\n",
      "Epoch [4/20], Step [201/915], Loss: 0.1413, Accuracy: 90.62%\n",
      "Epoch [4/20], Step [301/915], Loss: 0.3110, Accuracy: 65.62%\n",
      "Epoch [4/20], Step [401/915], Loss: 0.2552, Accuracy: 75.00%\n",
      "Epoch [4/20], Step [501/915], Loss: 0.2293, Accuracy: 78.12%\n",
      "Epoch [4/20], Step [601/915], Loss: 0.2097, Accuracy: 78.12%\n",
      "Epoch [4/20], Step [701/915], Loss: 0.2182, Accuracy: 78.12%\n",
      "Epoch [4/20], Step [801/915], Loss: 0.2701, Accuracy: 75.00%\n",
      "Epoch [4/20], Step [901/915], Loss: 0.2374, Accuracy: 75.00%\n",
      "Train Accuracy of the model on the train rna: 80.24269355665699 %\n",
      "Test Accuracy of the model on the test rna: 77.3526689293428 %\n",
      "Epoch [5/20], Step [1/915], Loss: 0.0757, Accuracy: 93.75%\n",
      "Epoch [5/20], Step [101/915], Loss: 0.2046, Accuracy: 81.25%\n",
      "Epoch [5/20], Step [201/915], Loss: 0.2149, Accuracy: 78.12%\n",
      "Epoch [5/20], Step [301/915], Loss: 0.0737, Accuracy: 93.75%\n",
      "Epoch [5/20], Step [401/915], Loss: 0.2569, Accuracy: 75.00%\n",
      "Epoch [5/20], Step [501/915], Loss: 0.4511, Accuracy: 53.12%\n",
      "Epoch [5/20], Step [601/915], Loss: 0.1611, Accuracy: 84.38%\n",
      "Epoch [5/20], Step [701/915], Loss: 0.2170, Accuracy: 78.12%\n",
      "Epoch [5/20], Step [801/915], Loss: 0.3011, Accuracy: 68.75%\n",
      "Epoch [5/20], Step [901/915], Loss: 0.2262, Accuracy: 78.12%\n",
      "Train Accuracy of the model on the train rna: 80.91608272090241 %\n",
      "Test Accuracy of the model on the test rna: 78.46343721073742 %\n",
      "Epoch [6/20], Step [1/915], Loss: 0.1734, Accuracy: 84.38%\n",
      "Epoch [6/20], Step [101/915], Loss: 0.3148, Accuracy: 68.75%\n",
      "Epoch [6/20], Step [201/915], Loss: 0.0693, Accuracy: 93.75%\n",
      "Epoch [6/20], Step [301/915], Loss: 0.2031, Accuracy: 81.25%\n",
      "Epoch [6/20], Step [401/915], Loss: 0.1641, Accuracy: 81.25%\n",
      "Epoch [6/20], Step [501/915], Loss: 0.3440, Accuracy: 65.62%\n",
      "Epoch [6/20], Step [601/915], Loss: 0.4230, Accuracy: 56.25%\n",
      "Epoch [6/20], Step [701/915], Loss: 0.2070, Accuracy: 81.25%\n",
      "Epoch [6/20], Step [801/915], Loss: 0.3461, Accuracy: 65.62%\n",
      "Epoch [6/20], Step [901/915], Loss: 0.0820, Accuracy: 93.75%\n",
      "Train Accuracy of the model on the train rna: 81.89711160485386 %\n",
      "Test Accuracy of the model on the test rna: 79.32736809626658 %\n",
      "Epoch [7/20], Step [1/915], Loss: 0.1262, Accuracy: 87.50%\n",
      "Epoch [7/20], Step [101/915], Loss: 0.1662, Accuracy: 84.38%\n",
      "Epoch [7/20], Step [201/915], Loss: 0.1709, Accuracy: 84.38%\n",
      "Epoch [7/20], Step [301/915], Loss: 0.2019, Accuracy: 81.25%\n",
      "Epoch [7/20], Step [401/915], Loss: 0.1888, Accuracy: 81.25%\n",
      "Epoch [7/20], Step [501/915], Loss: 0.1844, Accuracy: 81.25%\n",
      "Epoch [7/20], Step [601/915], Loss: 0.2270, Accuracy: 78.12%\n",
      "Epoch [7/20], Step [701/915], Loss: 0.2009, Accuracy: 78.12%\n",
      "Epoch [7/20], Step [801/915], Loss: 0.3943, Accuracy: 59.38%\n",
      "Epoch [7/20], Step [901/915], Loss: 0.1647, Accuracy: 84.38%\n",
      "Train Accuracy of the model on the train rna: 83.18919842761922 %\n",
      "Test Accuracy of the model on the test rna: 80.09873495834618 %\n",
      "Epoch [8/20], Step [1/915], Loss: 0.1995, Accuracy: 81.25%\n",
      "Epoch [8/20], Step [101/915], Loss: 0.3150, Accuracy: 68.75%\n",
      "Epoch [8/20], Step [201/915], Loss: 0.2734, Accuracy: 71.88%\n",
      "Epoch [8/20], Step [301/915], Loss: 0.2961, Accuracy: 71.88%\n",
      "Epoch [8/20], Step [401/915], Loss: 0.1894, Accuracy: 81.25%\n",
      "Epoch [8/20], Step [501/915], Loss: 0.1593, Accuracy: 84.38%\n",
      "Epoch [8/20], Step [601/915], Loss: 0.2240, Accuracy: 78.12%\n",
      "Epoch [8/20], Step [701/915], Loss: 0.1000, Accuracy: 90.62%\n",
      "Epoch [8/20], Step [801/915], Loss: 0.2234, Accuracy: 78.12%\n",
      "Epoch [8/20], Step [901/915], Loss: 0.1517, Accuracy: 84.38%\n",
      "Train Accuracy of the model on the train rna: 82.63202871304051 %\n",
      "Test Accuracy of the model on the test rna: 79.66676951558162 %\n",
      "Epoch [9/20], Step [1/915], Loss: 0.0367, Accuracy: 96.88%\n",
      "Epoch [9/20], Step [101/915], Loss: 0.2385, Accuracy: 78.12%\n",
      "Epoch [9/20], Step [201/915], Loss: 0.1780, Accuracy: 81.25%\n",
      "Epoch [9/20], Step [301/915], Loss: 0.1325, Accuracy: 87.50%\n",
      "Epoch [9/20], Step [401/915], Loss: 0.2606, Accuracy: 75.00%\n",
      "Epoch [9/20], Step [501/915], Loss: 0.3659, Accuracy: 68.75%\n",
      "Epoch [9/20], Step [601/915], Loss: 0.1623, Accuracy: 84.38%\n",
      "Epoch [9/20], Step [701/915], Loss: 0.1908, Accuracy: 81.25%\n",
      "Epoch [9/20], Step [801/915], Loss: 0.1494, Accuracy: 84.38%\n",
      "Epoch [9/20], Step [901/915], Loss: 0.1597, Accuracy: 87.50%\n",
      "Train Accuracy of the model on the train rna: 73.45411040847718 %\n",
      "Test Accuracy of the model on the test rna: 71.95310089478556 %\n",
      "Epoch [10/20], Step [1/915], Loss: 0.2975, Accuracy: 71.88%\n",
      "Epoch [10/20], Step [101/915], Loss: 0.2927, Accuracy: 71.88%\n",
      "Epoch [10/20], Step [201/915], Loss: 0.1090, Accuracy: 90.62%\n",
      "Epoch [10/20], Step [301/915], Loss: 0.2078, Accuracy: 78.12%\n",
      "Epoch [10/20], Step [401/915], Loss: 0.2892, Accuracy: 71.88%\n",
      "Epoch [10/20], Step [501/915], Loss: 0.0975, Accuracy: 90.62%\n",
      "Epoch [10/20], Step [601/915], Loss: 0.2586, Accuracy: 75.00%\n",
      "Epoch [10/20], Step [701/915], Loss: 0.2137, Accuracy: 78.12%\n",
      "Epoch [10/20], Step [801/915], Loss: 0.1880, Accuracy: 81.25%\n",
      "Epoch [10/20], Step [901/915], Loss: 0.1341, Accuracy: 87.50%\n",
      "Train Accuracy of the model on the train rna: 85.13758331909075 %\n",
      "Test Accuracy of the model on the test rna: 81.67232335698858 %\n",
      "Epoch [11/20], Step [1/915], Loss: 0.0360, Accuracy: 96.88%\n",
      "Epoch [11/20], Step [101/915], Loss: 0.1008, Accuracy: 90.62%\n",
      "Epoch [11/20], Step [201/915], Loss: 0.2483, Accuracy: 75.00%\n",
      "Epoch [11/20], Step [301/915], Loss: 0.1264, Accuracy: 87.50%\n",
      "Epoch [11/20], Step [401/915], Loss: 0.2547, Accuracy: 75.00%\n",
      "Epoch [11/20], Step [501/915], Loss: 0.2082, Accuracy: 78.12%\n",
      "Epoch [11/20], Step [601/915], Loss: 0.1592, Accuracy: 84.38%\n",
      "Epoch [11/20], Step [701/915], Loss: 0.2219, Accuracy: 78.12%\n",
      "Epoch [11/20], Step [801/915], Loss: 0.0362, Accuracy: 96.88%\n",
      "Epoch [11/20], Step [901/915], Loss: 0.1224, Accuracy: 90.62%\n",
      "Train Accuracy of the model on the train rna: 85.57169714578704 %\n",
      "Test Accuracy of the model on the test rna: 82.2277074976859 %\n",
      "Epoch [12/20], Step [1/915], Loss: 0.1343, Accuracy: 87.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Step [101/915], Loss: 0.1820, Accuracy: 81.25%\n",
      "Epoch [12/20], Step [201/915], Loss: 0.1935, Accuracy: 81.25%\n",
      "Epoch [12/20], Step [301/915], Loss: 0.1609, Accuracy: 84.38%\n",
      "Epoch [12/20], Step [401/915], Loss: 0.1893, Accuracy: 81.25%\n",
      "Epoch [12/20], Step [501/915], Loss: 0.1592, Accuracy: 84.38%\n",
      "Epoch [12/20], Step [601/915], Loss: 0.2471, Accuracy: 75.00%\n",
      "Epoch [12/20], Step [701/915], Loss: 0.1081, Accuracy: 90.62%\n",
      "Epoch [12/20], Step [801/915], Loss: 0.2127, Accuracy: 78.12%\n",
      "Epoch [12/20], Step [901/915], Loss: 0.1893, Accuracy: 81.25%\n",
      "Train Accuracy of the model on the train rna: 81.62023585711844 %\n",
      "Test Accuracy of the model on the test rna: 78.06232644245603 %\n",
      "Epoch [13/20], Step [1/915], Loss: 0.1708, Accuracy: 84.38%\n",
      "Epoch [13/20], Step [101/915], Loss: 0.2644, Accuracy: 75.00%\n",
      "Epoch [13/20], Step [201/915], Loss: 0.1259, Accuracy: 87.50%\n",
      "Epoch [13/20], Step [301/915], Loss: 0.2505, Accuracy: 75.00%\n",
      "Epoch [13/20], Step [401/915], Loss: 0.1281, Accuracy: 87.50%\n",
      "Epoch [13/20], Step [501/915], Loss: 0.1267, Accuracy: 87.50%\n",
      "Epoch [13/20], Step [601/915], Loss: 0.2207, Accuracy: 78.12%\n",
      "Epoch [13/20], Step [701/915], Loss: 0.2955, Accuracy: 68.75%\n",
      "Epoch [13/20], Step [801/915], Loss: 0.2514, Accuracy: 75.00%\n",
      "Epoch [13/20], Step [901/915], Loss: 0.1425, Accuracy: 87.50%\n",
      "Train Accuracy of the model on the train rna: 86.05366603999316 %\n",
      "Test Accuracy of the model on the test rna: 82.50539956803455 %\n",
      "Epoch [14/20], Step [1/915], Loss: 0.4077, Accuracy: 59.38%\n",
      "Epoch [14/20], Step [101/915], Loss: 0.1233, Accuracy: 87.50%\n",
      "Epoch [14/20], Step [201/915], Loss: 0.1102, Accuracy: 90.62%\n",
      "Epoch [14/20], Step [301/915], Loss: 0.0385, Accuracy: 96.88%\n",
      "Epoch [14/20], Step [401/915], Loss: 0.2213, Accuracy: 78.12%\n",
      "Epoch [14/20], Step [501/915], Loss: 0.0991, Accuracy: 90.62%\n",
      "Epoch [14/20], Step [601/915], Loss: 0.1081, Accuracy: 90.62%\n",
      "Epoch [14/20], Step [701/915], Loss: 0.0433, Accuracy: 96.88%\n",
      "Epoch [14/20], Step [801/915], Loss: 0.0830, Accuracy: 93.75%\n",
      "Epoch [14/20], Step [901/915], Loss: 0.1390, Accuracy: 87.50%\n",
      "Train Accuracy of the model on the train rna: 86.42625192274824 %\n",
      "Test Accuracy of the model on the test rna: 82.50539956803455 %\n",
      "Epoch [15/20], Step [1/915], Loss: 0.0865, Accuracy: 90.62%\n",
      "Epoch [15/20], Step [101/915], Loss: 0.1548, Accuracy: 84.38%\n",
      "Epoch [15/20], Step [201/915], Loss: 0.1927, Accuracy: 81.25%\n",
      "Epoch [15/20], Step [301/915], Loss: 0.1581, Accuracy: 84.38%\n",
      "Epoch [15/20], Step [401/915], Loss: 0.0669, Accuracy: 93.75%\n",
      "Epoch [15/20], Step [501/915], Loss: 0.0962, Accuracy: 90.62%\n",
      "Epoch [15/20], Step [601/915], Loss: 0.2225, Accuracy: 78.12%\n",
      "Epoch [15/20], Step [701/915], Loss: 0.2309, Accuracy: 78.12%\n",
      "Epoch [15/20], Step [801/915], Loss: 0.0667, Accuracy: 93.75%\n",
      "Epoch [15/20], Step [901/915], Loss: 0.2134, Accuracy: 78.12%\n",
      "Train Accuracy of the model on the train rna: 86.44334301828748 %\n",
      "Test Accuracy of the model on the test rna: 82.04257945078679 %\n",
      "Epoch [16/20], Step [1/915], Loss: 0.1902, Accuracy: 81.25%\n",
      "Epoch [16/20], Step [101/915], Loss: 0.0041, Accuracy: 100.00%\n",
      "Epoch [16/20], Step [201/915], Loss: 0.0986, Accuracy: 90.62%\n",
      "Epoch [16/20], Step [301/915], Loss: 0.1180, Accuracy: 87.50%\n",
      "Epoch [16/20], Step [401/915], Loss: 0.1583, Accuracy: 84.38%\n",
      "Epoch [16/20], Step [501/915], Loss: 0.1582, Accuracy: 84.38%\n",
      "Epoch [16/20], Step [601/915], Loss: 0.2339, Accuracy: 78.12%\n",
      "Epoch [16/20], Step [701/915], Loss: 0.1235, Accuracy: 87.50%\n",
      "Epoch [16/20], Step [801/915], Loss: 0.1070, Accuracy: 90.62%\n",
      "Epoch [16/20], Step [901/915], Loss: 0.1319, Accuracy: 87.50%\n",
      "Train Accuracy of the model on the train rna: 82.65253802768757 %\n",
      "Test Accuracy of the model on the test rna: 79.54335081764887 %\n",
      "Epoch [17/20], Step [1/915], Loss: 0.2707, Accuracy: 71.88%\n",
      "Epoch [17/20], Step [101/915], Loss: 0.1314, Accuracy: 87.50%\n",
      "Epoch [17/20], Step [201/915], Loss: 0.0652, Accuracy: 93.75%\n",
      "Epoch [17/20], Step [301/915], Loss: 0.1893, Accuracy: 81.25%\n",
      "Epoch [17/20], Step [401/915], Loss: 0.1809, Accuracy: 81.25%\n",
      "Epoch [17/20], Step [501/915], Loss: 0.1289, Accuracy: 87.50%\n",
      "Epoch [17/20], Step [601/915], Loss: 0.1573, Accuracy: 84.38%\n",
      "Epoch [17/20], Step [701/915], Loss: 0.1574, Accuracy: 84.38%\n",
      "Epoch [17/20], Step [801/915], Loss: 0.1611, Accuracy: 84.38%\n",
      "Epoch [17/20], Step [901/915], Loss: 0.1448, Accuracy: 84.38%\n",
      "Train Accuracy of the model on the train rna: 87.01418560929756 %\n",
      "Test Accuracy of the model on the test rna: 82.56710891700094 %\n",
      "Epoch [18/20], Step [1/915], Loss: 0.2837, Accuracy: 71.88%\n",
      "Epoch [18/20], Step [101/915], Loss: 0.1913, Accuracy: 81.25%\n",
      "Epoch [18/20], Step [201/915], Loss: 0.1919, Accuracy: 81.25%\n",
      "Epoch [18/20], Step [301/915], Loss: 0.2234, Accuracy: 78.12%\n",
      "Epoch [18/20], Step [401/915], Loss: 0.1359, Accuracy: 87.50%\n",
      "Epoch [18/20], Step [501/915], Loss: 0.1584, Accuracy: 84.38%\n",
      "Epoch [18/20], Step [601/915], Loss: 0.0959, Accuracy: 90.62%\n",
      "Epoch [18/20], Step [701/915], Loss: 0.1590, Accuracy: 84.38%\n",
      "Epoch [18/20], Step [801/915], Loss: 0.0343, Accuracy: 96.88%\n",
      "Epoch [18/20], Step [901/915], Loss: 0.1938, Accuracy: 81.25%\n",
      "Train Accuracy of the model on the train rna: 85.85540933173816 %\n",
      "Test Accuracy of the model on the test rna: 82.59796359148412 %\n",
      "Epoch [19/20], Step [1/915], Loss: 0.1556, Accuracy: 84.38%\n",
      "Epoch [19/20], Step [101/915], Loss: 0.3166, Accuracy: 68.75%\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "train(cnntrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(train_acc, label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plt.plot(train_acc[200:], label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and plot\n",
    "torch.save(model.state_dict(), MODEL_STORE_PATH + 'conv_net_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
