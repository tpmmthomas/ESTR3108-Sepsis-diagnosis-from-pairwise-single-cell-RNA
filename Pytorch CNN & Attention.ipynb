{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 401 CNN\n",
    "\n",
    "View more, visit my tutorial page: https://morvanzhou.github.io/tutorials/\n",
    "My Youtube Channel: https://www.youtube.com/user/MorvanZhou\n",
    "\n",
    "Dependencies:\n",
    "* torch: 0.1.11\n",
    "* torchvision\n",
    "* matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for reading and displaying images\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Transformers\n",
    "from module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data set (small amount to test if it works first)\n",
    "\n",
    "xtrain = r\"data/training_sample_NoSparse.csv.gz\"\n",
    "ytrain = r\"data/training_label_NoSparse.csv.gz\"\n",
    "xtest = r\"data/testing_sample_NoSparse.csv.gz\"\n",
    "ytest = r\"data/testing_label_NoSparse.csv.gz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15161, 14094)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check balance\n",
    "samplesdf = pd.DataFrame()\n",
    "for df in  pd.read_csv(ytrain,compression =\"gzip\",delimiter=',', chunksize = 10000, header=0):\n",
    "    samplesdf = samplesdf.append(df)\n",
    "y_train = samplesdf.to_numpy()\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for x in y_train:\n",
    "    if x == 0:\n",
    "        num0 = num0 + 1\n",
    "    else:\n",
    "        num1 = num1 + 1\n",
    "num0,num1 #checking if it is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self,samples,labels,numrows):\n",
    "\n",
    "        self.data = pd.read_csv(samples,compression =\"gzip\",delimiter=',', nrows = numrows, header=0)\n",
    "        self.label = pd.read_csv(labels,compression =\"gzip\",delimiter=',', nrows = numrows, header=0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        rna = self.data.iloc[idx]\n",
    "        seplb = self.label.iloc[idx]\n",
    "        rna = np.array([rna])\n",
    "        seplb = np.array([seplb])\n",
    "        rna = rna.astype('double').reshape(-1,3273)\n",
    "        seplb = seplb.astype('long').reshape(-1)\n",
    "        sample = {'rna': rna, 'label': seplb}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(samples=xtrain,labels=ytrain,numrows = 29255)\n",
    "test_dataset = Dataset(samples = xtest,labels = ytest,numrows = 3241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 10             # train the training data n times, to save time, we just train 1 epoch\n",
    "LR = 0.001              # learning rate\n",
    "batch_size = 32\n",
    "wd = LR / EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (x,1, 8949)\n",
    "            nn.Conv1d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=4,            # n_filters\n",
    "                kernel_size=3,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=1,                  # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (x,64,8949)\n",
    "            nn.BatchNorm1d(4),\n",
    "            nn.ReLU(),                      # activation\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (x,64, 8949)\n",
    "            nn.Conv1d(4,4,3,1,1),            \n",
    "            nn.ReLU(),  \n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.MaxPool1d(kernel_size =2, stride=2,ceil_mode = True),                # output shape (x,64,4478)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         # input shape (x,64,4478)\n",
    "            nn.Conv1d(4, 4, 3, 1, 1),     # output shape (x,128,4478)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool1d(kernel_size =2, stride=2,ceil_mode = True),                # output shape (x,128,2238)\n",
    "        )\n",
    "        self.out = nn.Linear(3276 , 2)   # fully connected layer, output 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(1, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(4, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv1d(4, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (out): Linear(in_features=3276, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR, weight_decay = wd)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "if torch.cuda.is_available():\n",
    "    cnn = cnn.cuda()\n",
    "    loss_func = loss_func.cuda()\n",
    "cnn = cnn.double()    \n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetTransformer(nn.Module):\n",
    "    def __init__(self, dim_input, num_outputs, dim_output,\n",
    "            num_inds=32, dim_hidden=128, num_heads=4, ln=False):\n",
    "        super(SetTransformer, self).__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "                ISAB(dim_input, dim_hidden, num_heads, num_inds, ln=ln),\n",
    "                ISAB(dim_hidden, dim_hidden, num_heads, num_inds, ln=ln))\n",
    "        self.dec = nn.Sequential(\n",
    "                PMA(dim_hidden, num_heads, num_outputs, ln=ln),\n",
    "                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
    "                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
    "                nn.Linear(dim_hidden, dim_output))\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dec(self.enc(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SetTransformer(\n",
      "  (enc): Sequential(\n",
      "    (0): ISAB(\n",
      "      (mab0): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=3273, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=3273, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (mab1): MAB(\n",
      "        (fc_q): Linear(in_features=3273, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ISAB(\n",
      "      (mab0): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (mab1): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec): Sequential(\n",
      "    (0): PMA(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trans = SetTransformer(3273,2,1)\n",
    "if torch.cuda.is_available():\n",
    "    trans = trans.cuda()\n",
    "trans = trans.double()\n",
    "print(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in train_loader:\n",
    "            rna,labels = batch[\"rna\"], batch[\"label\"] \n",
    "            if torch.cuda.is_available():\n",
    "                rna = rna.cuda()\n",
    "                labels = labels.cuda()\n",
    "            labels = labels.reshape(-1)\n",
    "            outputs = model(rna)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predicted = predicted.reshape(-1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "           # print(total,correct)\n",
    "\n",
    "        print('Train Accuracy of the model on the train rna: {} %'.format((correct / total) * 100))\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in test_loader:\n",
    "            rna,labels = batch[\"rna\"], batch[\"label\"] \n",
    "            if torch.cuda.is_available():\n",
    "                rna = rna.cuda()\n",
    "                labels = labels.cuda()\n",
    "            labels = labels.reshape(-1)\n",
    "            outputs = model(rna)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predicted = predicted.reshape(-1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    #print(total,correct)\n",
    "\n",
    "        print('Test Accuracy of the model on the test rna: {} %'.format((correct / total) * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(model): \n",
    "    total_step = len(train_loader)\n",
    "    num_epoch = EPOCH\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            # Run the forward pass\n",
    "            rna,labels = batch[\"rna\"], batch[\"label\"] \n",
    "            if torch.cuda.is_available():\n",
    "                rna = rna.cuda()\n",
    "                labels = labels.cuda()\n",
    "            outputs = model(rna)\n",
    "            labels = labels.long()\n",
    "            #labels = labels.reshape(-1)\n",
    "            #print(outputs.shape)\n",
    "           # print(outputs)\n",
    "            #print(outputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            # Backprop and perform Adam optimisation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track the accuracy\n",
    "            total = labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            train_acc.append(correct / total)\n",
    "            if i == 914:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                        .format(epoch + 1, num_epoch , i + 1, total_step, loss.item(),\n",
    "                                (correct / total) * 100))\n",
    "        test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [915/915], Loss: 0.6917, Accuracy: 57.14%\n",
      "Train Accuracy of the model on the train rna: 51.84071098957443 %\n",
      "Test Accuracy of the model on the test rna: 50.601666152422084 %\n",
      "Epoch [2/10], Step [915/915], Loss: 0.6906, Accuracy: 71.43%\n",
      "Train Accuracy of the model on the train rna: 51.84071098957443 %\n",
      "Test Accuracy of the model on the test rna: 50.601666152422084 %\n",
      "Epoch [3/10], Step [915/915], Loss: 0.6978, Accuracy: 14.29%\n",
      "Train Accuracy of the model on the train rna: 51.84071098957443 %\n",
      "Test Accuracy of the model on the test rna: 50.601666152422084 %\n",
      "Epoch [4/10], Step [915/915], Loss: 0.6928, Accuracy: 57.14%\n",
      "Train Accuracy of the model on the train rna: 51.84071098957443 %\n",
      "Test Accuracy of the model on the test rna: 50.601666152422084 %\n",
      "Epoch [5/10], Step [915/915], Loss: 0.6957, Accuracy: 28.57%\n",
      "Train Accuracy of the model on the train rna: 51.84071098957443 %\n",
      "Test Accuracy of the model on the test rna: 50.601666152422084 %\n",
      "Epoch [6/10], Step [915/915], Loss: 0.6911, Accuracy: 71.43%\n",
      "Train Accuracy of the model on the train rna: 51.84071098957443 %\n",
      "Test Accuracy of the model on the test rna: 50.601666152422084 %\n",
      "Epoch [7/10], Step [915/915], Loss: 0.6900, Accuracy: 71.43%\n",
      "Train Accuracy of the model on the train rna: 51.84071098957443 %\n",
      "Test Accuracy of the model on the test rna: 50.601666152422084 %\n",
      "Epoch [8/10], Step [915/915], Loss: 0.6929, Accuracy: 42.86%\n",
      "Train Accuracy of the model on the train rna: 51.84071098957443 %\n",
      "Test Accuracy of the model on the test rna: 50.601666152422084 %\n",
      "Epoch [9/10], Step [915/915], Loss: 0.6958, Accuracy: 42.86%\n",
      "Train Accuracy of the model on the train rna: 51.84071098957443 %\n",
      "Test Accuracy of the model on the test rna: 50.601666152422084 %\n",
      "Epoch [10/10], Step [915/915], Loss: 0.6923, Accuracy: 57.14%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-57813f5523c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-69fa9b499fab>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     33\u001b[0m                         .format(epoch + 1, num_epoch , i + 1, total_step, loss.item(),\n\u001b[0;32m     34\u001b[0m                                 (correct / total) * 100))\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-df5f679ba252>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-cc29ad0c3762>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\ESTR3108-Sepsis-diagnosis-from-pairwise-single-cell-RNA\\module.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mISAB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\ESTR3108-Sepsis-diagnosis-from-pairwise-single-cell-RNA\\module.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, Q, K)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mdim_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim_V\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mQ_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mK_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mV_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "train(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWp0lEQVR4nO3dfXBV1bnH8e9jgkQKRYiAQMRAZaS8JYEDVLhaFBC4VnnRUrnMCFJFq5Qq42gUq1T7h3rtFZmqd7DeQpnegi8Dckctw4tUKzNCQGwFwQTEIRQoDRpJGZCX5/6RbXqIB0hyTnI4rN9n5kz2XnvtfZ6VzOR39l47O+buiIhIuM5LdwEiIpJeCgIRkcApCEREAqcgEBEJnIJARCRw2ekuoCEuuugiz8/PT3cZIiIZZcOGDf9w93a12zMyCPLz8ykpKUl3GSIiGcXMPkvUrktDIiKBUxCIiAROQSAiEriMnCMQkfo7evQo5eXlHD58ON2lSCPLyckhLy+PZs2a1am/gkAkEOXl5bRq1Yr8/HzMLN3lSCNxdyoqKigvL6dr16512keXhkQCcfjwYXJzcxUC5zgzIzc3t15nfgoCkYAoBMJQ35+zgkBEJHAKAhFpEhUVFRQWFlJYWMjFF19M586da9a/+uqr0+5bUlLCjBkzzvgegwcPTkmta9as4Qc/+EFKjpUJNFksIk0iNzeXTZs2ATB79mxatmzJfffdV7P92LFjZGcn/pUUi8WIxWJnfI+1a9empNbQ6IxARNJmypQp3HnnnQwaNIj777+fdevWccUVV1BUVMTgwYPZtm0bcPIn9NmzZzN16lSGDh1Kt27dmDt3bs3xWrZsWdN/6NCh3HTTTfTo0YNJkybx9X9jfPPNN+nRowf9+/dnxowZZ/zkf+DAAcaOHUvfvn353ve+x1/+8hcA/vSnP9Wc0RQVFXHw4EH27NnDVVddRWFhIb179+bdd99N+fesMeiMQCRAv/i/zWz525cpPWbPTt/m0et71Xu/8vJy1q5dS1ZWFl9++SXvvvsu2dnZrFy5koceeojXXnvtG/ts3bqVt99+m4MHD3L55Zfzk5/85Bv3zH/wwQds3ryZTp06MWTIEN577z1isRh33HEH77zzDl27dmXixIlnrO/RRx+lqKiIpUuXsnr1am655RY2bdrE008/zXPPPceQIUOoqqoiJyeHefPmMXLkSGbNmsXx48c5dOhQvb8f6aAgEJG0+uEPf0hWVhYAlZWVTJ48mdLSUsyMo0ePJtznuuuuo3nz5jRv3pz27duzb98+8vLyTuozcODAmrbCwkJ27txJy5Yt6datW8399RMnTmTevHmnre/Pf/5zTRhdc801VFRU8OWXXzJkyBBmzpzJpEmTGD9+PHl5eQwYMICpU6dy9OhRxo4dS2FhYTLfmiajIBAJUEM+uTeWb33rWzXLP//5z7n66qtZsmQJO3fuZOjQoQn3ad68ec1yVlYWx44da1CfZBQXF3Pdddfx5ptvMmTIEJYvX85VV13FO++8wxtvvMGUKVOYOXMmt9xyS0rftzFojkBEzhqVlZV07twZgPnz56f8+Jdffjk7duxg586dACxevPiM+1x55ZX8/ve/B6rnHi666CK+/e1vs337dvr06cMDDzzAgAED2Lp1K5999hkdOnTg9ttv57bbbmPjxo0pH0NjUBCIyFnj/vvv58EHH6SoqCjln+ABLrjgAp5//nlGjRpF//79adWqFa1btz7tPrNnz2bDhg307duX4uJiFixYAMCcOXPo3bs3ffv2pVmzZowePZo1a9ZQUFBAUVERixcv5mc/+1nKx9AY7OuZ9EwSi8Vc/5hGpH4+/vhjvvvd76a7jLSrqqqiZcuWuDt333033bt359577013WSmX6OdtZhvc/Rv34eqMQESC8uKLL1JYWEivXr2orKzkjjvuSHdJaafJYhEJyr333ntOngEkQ2cEIiKBUxCIiAROQSAiEjgFgYhI4BQEItIkMukx1KHRXUMi0iT0GOrEjh8/XvOspXRJyRmBmY0ys21mVmZmxQm2NzezxdH2980sv9b2LmZWZWb31d5XRM5dZ+tjqHfu3MmVV15Jv3796Nev30kB8+STT9KnTx8KCgooLq7+dVdWVsbw4cMpKCigX79+bN++/Rv/3Gb69Ok1j83Iz8/ngQceoF+/frzyyiu8+OKLDBgwgIKCAm688caap5bu27ePcePGUVBQQEFBAWvXruWRRx5hzpw5NcedNWsWzz77bFI/h6TPCMwsC3gOGAGUA+vNbJm7b4nr9mPgc3e/zMxuBp4EfhS3/b+At5KtRUTq6K1i2PvX1B7z4j4w+ol673Y2Poa6ffv2rFixgpycHEpLS5k4cSIlJSW89dZbvP7667z//vu0aNGCAwcOADBp0iSKi4sZN24chw8f5sSJE+zateu0487Nza15FlFFRQW33347AA8//DAvvfQSP/3pT5kxYwbf//73WbJkCcePH6eqqopOnToxfvx47rnnHk6cOMGiRYtYt25dvb/v8VJxaWggUObuOwDMbBEwBogPgjHA7Gj5VeDXZmbu7mY2FvgU+GcKahGRDHM2Pob66NGjTJ8+nU2bNpGVlcUnn3wCwMqVK7n11ltp0aIFAG3btuXgwYPs3r2bcePGAZCTk1Oncf/oR//6LPzRRx/x8MMP88UXX1BVVcXIkSMBWL16Nb/73e+A6ieotm7dmtatW5Obm8sHH3zAvn37KCoqIjc3t07veSqpCILOQHz0lQODTtXH3Y+ZWSWQa2aHgQeoPps47WUhM5sGTAPo0qVLCsoWCVgDPrk3lrPxMdTPPPMMHTp04MMPP+TEiRN1/uUeLzs7mxMnTtSsHz58+KTt8eOeMmUKS5cupaCggPnz57NmzZrTHvu2225j/vz57N27l6lTp9a7ttrSfdfQbOAZd686U0d3n+fuMXePtWvXrvErE5Emd7Y8hrqyspKOHTty3nnnsXDhQo4fPw7AiBEj+O1vf1tzDf/AgQO0atWKvLw8li5dCsCRI0c4dOgQl156KVu2bOHIkSN88cUXrFq16pR1HTx4kI4dO3L06NGaR14DDBs2jBdeeAGonlSurKwEYNy4cfzxj39k/fr1NWcPyUhFEOwGLolbz4vaEvYxs2ygNVBB9ZnDU2a2E7gHeMjMpqegJhHJQGfLY6jvuusuFixYQEFBAVu3bq359D5q1ChuuOEGYrEYhYWFPP300wAsXLiQuXPn0rdvXwYPHszevXu55JJLmDBhAr1792bChAkUFRWdsq7HH3+cQYMGMWTIEHr06FHT/uyzz/L222/Tp08f+vfvz5Yt1Vfczz//fK6++momTJiQkjuOkn4MdfSL/RNgGNW/8NcD/+Hum+P63A30cfc7o8ni8e4+odZxZgNV7v70md5Tj6EWqT89hrraufAY6hMnTtTccdS9e/eEfZr0MdTufgyYDiwHPgZedvfNZvaYmd0QdXuJ6jmBMmAm8I1bTEVEmkKmP4Z6y5YtXHbZZQwbNuyUIVBf+sc0IoHQGUFY9I9pRCShTPzgJ/VX35+zgkAkEDk5OVRUVCgMznHuTkVFRb1uedWzhkQCkZeXR3l5Ofv37093KdLIcnJyvvEHdqejIBAJRLNmzWr+olYkni4NiYgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhI4BYGISOAUBCIigVMQiIgETkEgIhK4lASBmY0ys21mVmZmxQm2NzezxdH2980sP2ofYWYbzOyv0ddrUlGPiIjUXdJBYGZZwHPAaKAnMNHMetbq9mPgc3e/DHgGeDJq/wdwvbv3ASYDC5OtR0RE6icVZwQDgTJ33+HuXwGLgDG1+owBFkTLrwLDzMzc/QN3/1vUvhm4wMyap6AmERGpo1QEQWdgV9x6edSWsI+7HwMqgdxafW4ENrr7kRTUJCIidZSd7gIAzKwX1ZeLrj1Nn2nANIAuXbo0UWUiIue+VJwR7AYuiVvPi9oS9jGzbKA1UBGt5wFLgFvcffup3sTd57l7zN1j7dq1S0HZIiICqQmC9UB3M+tqZucDNwPLavVZRvVkMMBNwGp3dzO7EHgDKHb391JQi4iI1FPSQRBd858OLAc+Bl52981m9piZ3RB1ewnINbMyYCbw9S2m04HLgEfMbFP0ap9sTSIiUnfm7umuod5isZiXlJSkuwwRkYxiZhvcPVa7XX9ZLCISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFLSRCY2Sgz22ZmZWZWnGB7czNbHG1/38zy47Y9GLVvM7ORqahHRETqLukgMLMs4DlgNNATmGhmPWt1+zHwubtfBjwDPBnt2xO4GegFjAKej44nIiJNJBVnBAOBMnff4e5fAYuAMbX6jAEWRMuvAsPMzKL2Re5+xN0/Bcqi44mISBNJRRB0BnbFrZdHbQn7uPsxoBLIreO+AJjZNDMrMbOS/fv3p6BsERGBDJosdvd57h5z91i7du3SXY6IyDkjFUGwG7gkbj0vakvYx8yygdZARR33FRGRRpSKIFgPdDezrmZ2PtWTv8tq9VkGTI6WbwJWu7tH7TdHdxV1BboD61JQk4iI1FF2sgdw92NmNh1YDmQB/+Pum83sMaDE3ZcBLwELzawMOEB1WBD1exnYAhwD7nb348nWJCIidWfVH8wzSywW85KSknSXISKSUcxsg7vHardnzGSxiIg0DgWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgFAQiIoFTEIiIBE5BICISOAWBiEjgkgoCM2trZivMrDT62uYU/SZHfUrNbHLU1sLM3jCzrWa22cyeSKYWERFpmGTPCIqBVe7eHVgVrZ/EzNoCjwKDgIHAo3GB8bS79wCKgCFmNjrJekREpJ6SDYIxwIJoeQEwNkGfkcAKdz/g7p8DK4BR7n7I3d8GcPevgI1AXpL1iIhIPSUbBB3cfU+0vBfokKBPZ2BX3Hp51FbDzC4Erqf6rEJERJpQ9pk6mNlK4OIEm2bFr7i7m5nXtwAzywb+AMx19x2n6TcNmAbQpUuX+r6NiIicwhmDwN2Hn2qbme0zs47uvsfMOgJ/T9BtNzA0bj0PWBO3Pg8odfc5Z6hjXtSXWCxW78AREZHEkr00tAyYHC1PBl5P0Gc5cK2ZtYkmia+N2jCzXwKtgXuSrENERBoo2SB4AhhhZqXA8GgdM4uZ2W8A3P0A8DiwPno95u4HzCyP6stLPYGNZrbJzG5Lsh4REaknc8+8qyyxWMxLSkrSXYaISEYxsw3uHqvdrr8sFhEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcApCEREAqcgEBEJnIJARCRwCgIRkcAlFQRm1tbMVphZafS1zSn6TY76lJrZ5ATbl5nZR8nUIiIiDZPsGUExsMrduwOrovWTmFlb4FFgEDAQeDQ+MMxsPFCVZB0iItJAyQbBGGBBtLwAGJugz0hghbsfcPfPgRXAKAAzawnMBH6ZZB0iItJAyQZBB3ffEy3vBTok6NMZ2BW3Xh61ATwO/Ao4dKY3MrNpZlZiZiX79+9PomQREYmXfaYOZrYSuDjBplnxK+7uZuZ1fWMzKwS+4+73mln+mfq7+zxgHkAsFqvz+4iIyOmdMQjcffiptpnZPjPr6O57zKwj8PcE3XYDQ+PW84A1wBVAzMx2RnW0N7M17j4UERFpMsleGloGfH0X0GTg9QR9lgPXmlmbaJL4WmC5u7/g7p3cPR/4N+AThYCISNNLNgieAEaYWSkwPFrHzGJm9hsAdz9A9VzA+uj1WNQmIiJnAXPPvMvtsVjMS0pK0l2GiEhGMbMN7h6r3a6/LBYRCZyCQEQkcAoCEZHAKQhERAKnIBARCZyCQEQkcAoCEZHAKQhERAKnIBARCZyCQEQkcAoCEZHAKQhERAKnIBARCZyCQEQkcAoCEZHAKQhERAKnIBARCZyCQEQkcAoCEZHAKQhERAKnIBARCZyCQEQkcAoCEZHAKQhERAJn7p7uGurNzPYDn6W7jnq6CPhHuotoYhpzGDTmzHGpu7er3ZiRQZCJzKzE3WPprqMpacxh0Jgzny4NiYgETkEgIhI4BUHTmZfuAtJAYw6DxpzhNEcgIhI4nRGIiAROQSAiEjgFQQqZWVszW2FmpdHXNqfoNznqU2pmkxNsX2ZmHzV+xclLZsxm1sLM3jCzrWa22cyeaNrq68fMRpnZNjMrM7PiBNubm9niaPv7ZpYft+3BqH2bmY1s0sKT0NAxm9kIM9tgZn+Nvl7T5MU3QDI/42h7FzOrMrP7mqzoVHB3vVL0Ap4CiqPlYuDJBH3aAjuir22i5TZx28cD/wt8lO7xNPaYgRbA1VGf84F3gdHpHtMpxpkFbAe6RbV+CPSs1ecu4L+j5ZuBxdFyz6h/c6BrdJysdI+pkcdcBHSKlnsDu9M9nsYcb9z2V4FXgPvSPZ76vHRGkFpjgAXR8gJgbII+I4EV7n7A3T8HVgCjAMysJTAT+GXjl5oyDR6zux9y97cB3P0rYCOQ1/glN8hAoMzdd0S1LqJ67PHivxevAsPMzKL2Re5+xN0/Bcqi453tGjxmd//A3f8WtW8GLjCz5k1SdcMl8zPGzMYCn1I93oyiIEitDu6+J1reC3RI0KczsCtuvTxqA3gc+BVwqNEqTL1kxwyAmV0IXA+saoQaU+GMY4jv4+7HgEogt477no2SGXO8G4GN7n6kkepMlQaPN/oQ9wDwiyaoM+Wy011ApjGzlcDFCTbNil9xdzezOt+ba2aFwHfc/d7a1x3TrbHGHHf8bOAPwFx339GwKuVsZGa9gCeBa9NdSyObDTzj7lXRCUJGURDUk7sPP9U2M9tnZh3dfY+ZdQT+nqDbbmBo3HoesAa4AoiZ2U6qfy7tzWyNuw8lzRpxzF+bB5S6+5zkq200u4FL4tbzorZEfcqjcGsNVNRx37NRMmPGzPKAJcAt7r698ctNWjLjHQTcZGZPARcCJ8zssLv/utGrToV0T1KcSy/gPzl54vSpBH3aUn0dsU30+hRoW6tPPpkzWZzUmKmeD3kNOC/dYznDOLOpnuTuyr8mEnvV6nM3J08kvhwt9+LkyeIdZMZkcTJjvjDqPz7d42iK8dbqM5sMmyxOewHn0ovqa6OrgFJgZdwvuxjwm7h+U6meMCwDbk1wnEwKggaPmepPXA58DGyKXrele0ynGeu/A59QfWfJrKjtMeCGaDmH6jtGyoB1QLe4fWdF+23jLL0zKpVjBh4G/hn3c90EtE/3eBrzZxx3jIwLAj1iQkQkcLprSEQkcAoCEZHAKQhERAKnIBARCZyCQEQkcAoCEZHAKQhERAL3/wJzYCBVH5fAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses[200:], label='Training loss')\n",
    "plt.plot(train_acc[200:], label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#plt.plot(train_acc[200:], label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-bd31bee9d1a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Save the model and plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMODEL_STORE_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'conv_net_model.ckpt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the model and plot\n",
    "torch.save(model.state_dict(), MODEL_STORE_PATH + 'conv_net_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
