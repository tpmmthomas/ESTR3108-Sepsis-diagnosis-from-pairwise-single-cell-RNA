{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# for reading and displaying images\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Transformers\n",
    "from module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data set (small amount to test if it works first)\n",
    "\n",
    "xtrain = r\"data/training_sample_NoSparse.csv.gz\"\n",
    "ytrain = r\"data/training_label_NoSparse.csv.gz\"\n",
    "xtest = r\"data/testing_sample_NoSparse.csv.gz\"\n",
    "ytest = r\"data/testing_label_NoSparse.csv.gz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15161, 14094)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check balance\n",
    "samplesdf = pd.DataFrame()\n",
    "for df in  pd.read_csv(ytrain,compression =\"gzip\",delimiter=',', chunksize = 10000, header=0):\n",
    "    samplesdf = samplesdf.append(df)\n",
    "y_train = samplesdf.to_numpy()\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for x in y_train:\n",
    "    if x == 0:\n",
    "        num0 = num0 + 1\n",
    "    else:\n",
    "        num1 = num1 + 1\n",
    "num0,num1 #checking if it is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.   ... 3.11 0.   3.69]\n",
      " [0.   0.   0.   ... 3.16 0.   3.33]\n",
      " [0.   0.   0.   ... 2.98 0.   3.64]\n",
      " ...\n",
      " [1.39 0.   0.   ... 1.95 0.   3.57]\n",
      " [0.   2.08 0.   ... 2.71 0.   3.09]\n",
      " [0.   0.   0.   ... 3.12 0.   2.85]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(xtrain,compression =\"gzip\",delimiter=',', nrows=123, header=0)\n",
    "x_train = df.to_numpy()\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self,samples,labels,numrows):\n",
    "\n",
    "        self.data = pd.read_csv(samples,compression =\"gzip\",delimiter=',', nrows = numrows, header=0)\n",
    "        self.label = pd.read_csv(labels,compression =\"gzip\",delimiter=',', nrows = numrows, header=0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        rna = self.data.iloc[idx]\n",
    "        seplb = self.label.iloc[idx]\n",
    "        rna = np.array([rna])\n",
    "        seplb = np.array([seplb])\n",
    "        rna = rna.astype('double').reshape(-1,3273)\n",
    "        sample = {'rna': rna, 'label': seplb}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(samples=xtrain,labels=ytrain,numrows = 29255)\n",
    "test_dataset = Dataset(samples = xtest,labels = ytest,numrows = 3241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 10             # train the training data n times, to save time, we just train 1 epoch\n",
    "LR = 0.005              # learning rate\n",
    "batch_size = 32\n",
    "wd = LR / EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (x,1, 8949)\n",
    "            nn.Conv1d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=4,            # n_filters\n",
    "                kernel_size=3,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=1,                  # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (x,64,8949)\n",
    "            nn.BatchNorm1d(4),\n",
    "            nn.ReLU(),                      # activation\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (x,64, 8949)\n",
    "            nn.Conv1d(4,4,3,1,1),            \n",
    "            nn.ReLU(),  \n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.MaxPool1d(kernel_size =2, stride=2,ceil_mode = True),                # output shape (x,64,4478)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         # input shape (x,64,4478)\n",
    "            nn.Conv1d(4, 4, 3, 1, 1),     # output shape (x,128,4478)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool1d(kernel_size =2, stride=2,ceil_mode = True),                # output shape (x,128,2238)\n",
    "        )\n",
    "        self.out = nn.Linear(3276 , 2)   # fully connected layer, output 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cnn = CNN()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "if torch.cuda.is_available():\n",
    "    cnn = cnn.cuda()\n",
    "    loss_func = loss_func.cuda()\n",
    "cnn = cnn.double()    \n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetTransformer(nn.Module):\n",
    "    def __init__(self, dim_input, num_outputs, dim_output,\n",
    "            num_inds=32, dim_hidden=128, num_heads=2, ln=False):\n",
    "        super(SetTransformer, self).__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "                ISAB(dim_input, dim_hidden, num_heads, num_inds, ln=ln),\n",
    "                ISAB(dim_hidden, dim_hidden, num_heads, num_inds, ln=ln))\n",
    "        self.dec = nn.Sequential(\n",
    "                PMA(dim_hidden, num_heads, num_outputs, ln=ln),\n",
    "                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
    "                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
    "                nn.Linear(dim_hidden, dim_output))\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dec(self.enc(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trans = SetTransformer(3273,2,1)\n",
    "optimizer = torch.optim.Adam(trans.parameters(), lr=LR)   \n",
    "loss_func = nn.CrossEntropyLoss()                      \n",
    "if torch.cuda.is_available():\n",
    "    loss_func = loss_func.cuda()\n",
    "    trans = trans.cuda()\n",
    "trans = trans.double()\n",
    "print(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Trans(nn.Module):\n",
    "    def __init__(self, dim_input, num_outputs, dim_output,\n",
    "            num_inds=32, dim_hidden=128, num_heads=4, ln=False):\n",
    "        super(CNN_Trans, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (x,1, 8949)\n",
    "            nn.Conv1d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=4,            # n_filters\n",
    "                kernel_size=3,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=1,                  # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (x,64,8949)\n",
    "            nn.BatchNorm1d(4),\n",
    "            nn.ReLU(),                      # activation\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (x,64, 8949)\n",
    "            nn.Conv1d(4,4,3,1,1),            \n",
    "            nn.ReLU(),  \n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.MaxPool1d(kernel_size =2, stride=2,ceil_mode = True),                # output shape (x,64,4478)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         # input shape (x,64,4478)\n",
    "            nn.Conv1d(4, 4, 3, 1, 1),     # output shape (x,128,4478)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool1d(kernel_size =2, stride=2,ceil_mode = True),                # output shape (x,128,2238)\n",
    "        )\n",
    "        self.enc = nn.Sequential(\n",
    "                ISAB(dim_input, dim_hidden, num_heads, num_inds, ln=ln),\n",
    "                ISAB(dim_hidden, dim_hidden, num_heads, num_inds, ln=ln))\n",
    "        self.dec = nn.Sequential(\n",
    "                PMA(dim_hidden, num_heads, num_outputs, ln=ln),\n",
    "                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
    "                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
    "                nn.Linear(dim_hidden, dim_output))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = x.reshape(-1,1,3276)\n",
    "        return self.dec(self.enc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Trans(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(1, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(4, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv1d(4, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (enc): Sequential(\n",
      "    (0): ISAB(\n",
      "      (mab0): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=3276, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=3276, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (mab1): MAB(\n",
      "        (fc_q): Linear(in_features=3276, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ISAB(\n",
      "      (mab0): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (mab1): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec): Sequential(\n",
      "    (0): PMA(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnntrans = CNN_Trans(3276,1,2)\n",
    "optimizer = torch.optim.Adam(cnntrans.parameters(), lr=LR)   \n",
    "loss_func = nn.CrossEntropyLoss()                      \n",
    "if torch.cuda.is_available():\n",
    "    loss_func = loss_func.cuda()\n",
    "    cnntrans = cnntrans.cuda()\n",
    "cnntrans = cnntrans.double()\n",
    "print(cnntrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in train_loader:\n",
    "            rna,labels = batch[\"rna\"], batch[\"label\"] \n",
    "            if torch.cuda.is_available():\n",
    "                rna = rna.cuda()\n",
    "                labels = labels.cuda()\n",
    "            labels = labels.reshape(-1)\n",
    "            outputs = model(rna)\n",
    "            outputs = outputs.reshape(-1,2)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "           # print(total,correct)\n",
    "\n",
    "        print('Train Accuracy of the model on the train rna: {} %'.format((correct / total) * 100))\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in test_loader:\n",
    "            rna,labels = batch[\"rna\"], batch[\"label\"] \n",
    "            if torch.cuda.is_available():\n",
    "                rna = rna.cuda()\n",
    "                labels = labels.cuda()\n",
    "            labels = labels.reshape(-1)\n",
    "            outputs = model(rna)\n",
    "            outputs = outputs.reshape(-1,2)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    #print(total,correct)\n",
    "\n",
    "        print('Test Accuracy of the model on the test rna: {} %'.format((correct / total) * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(model): \n",
    "    total_step = len(train_loader)\n",
    "    num_epoch = EPOCH\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            # Run the forward pass\n",
    "            rna,labels = batch[\"rna\"], batch[\"label\"] \n",
    "            if torch.cuda.is_available():\n",
    "                rna = rna.cuda()\n",
    "                labels = labels.cuda()\n",
    "            outputs = model(rna)\n",
    "            labels = labels.long()\n",
    "            #print(outputs)\n",
    "            outputs = outputs.reshape(-1,2)\n",
    "            labels = labels.reshape(-1)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            # Backprop and perform Adam optimisation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track the accuracy\n",
    "            total = labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            train_acc.append(correct / total)\n",
    "            if i % 100 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                        .format(epoch + 1, num_epoch , i + 1, total_step, loss.item(),\n",
    "                                (correct / total) * 100))\n",
    "        test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [1/915], Loss: 0.7219, Accuracy: 37.50%\n",
      "Epoch [1/10], Step [101/915], Loss: 0.6969, Accuracy: 40.62%\n",
      "Epoch [1/10], Step [201/915], Loss: 0.6550, Accuracy: 62.50%\n",
      "Epoch [1/10], Step [301/915], Loss: 0.7469, Accuracy: 53.12%\n",
      "Epoch [1/10], Step [401/915], Loss: 0.5721, Accuracy: 59.38%\n",
      "Epoch [1/10], Step [501/915], Loss: 0.5288, Accuracy: 68.75%\n",
      "Epoch [1/10], Step [601/915], Loss: 0.4613, Accuracy: 75.00%\n",
      "Epoch [1/10], Step [701/915], Loss: 0.4649, Accuracy: 78.12%\n",
      "Epoch [1/10], Step [801/915], Loss: 0.4419, Accuracy: 81.25%\n",
      "Epoch [1/10], Step [901/915], Loss: 0.5921, Accuracy: 65.62%\n",
      "Train Accuracy of the model on the train rna: 76.4074517176551 %\n",
      "Test Accuracy of the model on the test rna: 74.69916692378895 %\n",
      "Epoch [2/10], Step [1/915], Loss: 0.5291, Accuracy: 75.00%\n",
      "Epoch [2/10], Step [101/915], Loss: 0.4153, Accuracy: 84.38%\n",
      "Epoch [2/10], Step [201/915], Loss: 0.4168, Accuracy: 78.12%\n",
      "Epoch [2/10], Step [301/915], Loss: 0.5473, Accuracy: 75.00%\n",
      "Epoch [2/10], Step [401/915], Loss: 0.4245, Accuracy: 78.12%\n",
      "Epoch [2/10], Step [501/915], Loss: 0.5285, Accuracy: 75.00%\n",
      "Epoch [2/10], Step [601/915], Loss: 0.6010, Accuracy: 71.88%\n",
      "Epoch [2/10], Step [701/915], Loss: 0.6184, Accuracy: 62.50%\n",
      "Epoch [2/10], Step [801/915], Loss: 0.2813, Accuracy: 93.75%\n",
      "Epoch [2/10], Step [901/915], Loss: 0.5383, Accuracy: 81.25%\n",
      "Train Accuracy of the model on the train rna: 76.3014869253119 %\n",
      "Test Accuracy of the model on the test rna: 73.40327059549521 %\n",
      "Epoch [3/10], Step [1/915], Loss: 0.4616, Accuracy: 84.38%\n",
      "Epoch [3/10], Step [101/915], Loss: 0.4233, Accuracy: 81.25%\n",
      "Epoch [3/10], Step [201/915], Loss: 0.3293, Accuracy: 87.50%\n",
      "Epoch [3/10], Step [301/915], Loss: 0.3123, Accuracy: 87.50%\n",
      "Epoch [3/10], Step [401/915], Loss: 0.4044, Accuracy: 78.12%\n",
      "Epoch [3/10], Step [501/915], Loss: 0.3534, Accuracy: 81.25%\n",
      "Epoch [3/10], Step [601/915], Loss: 0.4933, Accuracy: 78.12%\n",
      "Epoch [3/10], Step [701/915], Loss: 0.2188, Accuracy: 93.75%\n",
      "Epoch [3/10], Step [801/915], Loss: 0.2582, Accuracy: 90.62%\n",
      "Epoch [3/10], Step [901/915], Loss: 0.4244, Accuracy: 78.12%\n",
      "Train Accuracy of the model on the train rna: 84.42659374465903 %\n",
      "Test Accuracy of the model on the test rna: 82.16599814871954 %\n",
      "Epoch [4/10], Step [1/915], Loss: 0.2872, Accuracy: 87.50%\n",
      "Epoch [4/10], Step [101/915], Loss: 0.5438, Accuracy: 65.62%\n",
      "Epoch [4/10], Step [201/915], Loss: 0.3791, Accuracy: 87.50%\n",
      "Epoch [4/10], Step [301/915], Loss: 0.3082, Accuracy: 81.25%\n",
      "Epoch [4/10], Step [401/915], Loss: 0.4480, Accuracy: 75.00%\n",
      "Epoch [4/10], Step [501/915], Loss: 0.9598, Accuracy: 71.88%\n",
      "Epoch [4/10], Step [601/915], Loss: 0.4817, Accuracy: 71.88%\n",
      "Epoch [4/10], Step [701/915], Loss: 0.4704, Accuracy: 78.12%\n",
      "Epoch [4/10], Step [801/915], Loss: 0.3824, Accuracy: 84.38%\n",
      "Epoch [4/10], Step [901/915], Loss: 0.3162, Accuracy: 84.38%\n",
      "Train Accuracy of the model on the train rna: 72.44231755255511 %\n",
      "Test Accuracy of the model on the test rna: 71.30515273063868 %\n",
      "Epoch [5/10], Step [1/915], Loss: 0.8544, Accuracy: 71.88%\n",
      "Epoch [5/10], Step [101/915], Loss: 170226.2065, Accuracy: 50.00%\n",
      "Epoch [5/10], Step [201/915], Loss: 15309.9245, Accuracy: 53.12%\n",
      "Epoch [5/10], Step [301/915], Loss: 14192.6117, Accuracy: 50.00%\n",
      "Epoch [5/10], Step [401/915], Loss: 1848.5677, Accuracy: 62.50%\n",
      "Epoch [5/10], Step [501/915], Loss: 1434.2774, Accuracy: 56.25%\n",
      "Epoch [5/10], Step [601/915], Loss: 567.7186, Accuracy: 62.50%\n",
      "Epoch [5/10], Step [701/915], Loss: 2200.9923, Accuracy: 50.00%\n",
      "Epoch [5/10], Step [801/915], Loss: 666.1669, Accuracy: 65.62%\n",
      "Epoch [5/10], Step [901/915], Loss: 1274.0755, Accuracy: 50.00%\n",
      "Train Accuracy of the model on the train rna: 51.82361989403521 %\n",
      "Test Accuracy of the model on the test rna: 50.5708114779389 %\n",
      "Epoch [6/10], Step [1/915], Loss: 1113.6863, Accuracy: 50.00%\n",
      "Epoch [6/10], Step [101/915], Loss: 610.4050, Accuracy: 43.75%\n",
      "Epoch [6/10], Step [201/915], Loss: 634.2862, Accuracy: 46.88%\n",
      "Epoch [6/10], Step [301/915], Loss: 407.9576, Accuracy: 68.75%\n",
      "Epoch [6/10], Step [401/915], Loss: 332.5591, Accuracy: 37.50%\n",
      "Epoch [6/10], Step [501/915], Loss: 499.4650, Accuracy: 59.38%\n",
      "Epoch [6/10], Step [601/915], Loss: 330.9128, Accuracy: 59.38%\n",
      "Epoch [6/10], Step [701/915], Loss: 272.1060, Accuracy: 43.75%\n",
      "Epoch [6/10], Step [801/915], Loss: 104.9928, Accuracy: 68.75%\n",
      "Epoch [6/10], Step [901/915], Loss: 165.1296, Accuracy: 40.62%\n",
      "Train Accuracy of the model on the train rna: 48.176380105964796 %\n",
      "Test Accuracy of the model on the test rna: 49.42918852206109 %\n",
      "Epoch [7/10], Step [1/915], Loss: 138.8181, Accuracy: 34.38%\n",
      "Epoch [7/10], Step [101/915], Loss: 81.6281, Accuracy: 43.75%\n",
      "Epoch [7/10], Step [201/915], Loss: 16.0729, Accuracy: 37.50%\n",
      "Epoch [7/10], Step [301/915], Loss: 1884.3695, Accuracy: 62.50%\n",
      "Epoch [7/10], Step [401/915], Loss: 60.2805, Accuracy: 56.25%\n",
      "Epoch [7/10], Step [501/915], Loss: 29.6266, Accuracy: 56.25%\n",
      "Epoch [7/10], Step [601/915], Loss: 120.2421, Accuracy: 37.50%\n",
      "Epoch [7/10], Step [701/915], Loss: 375.2884, Accuracy: 46.88%\n",
      "Epoch [7/10], Step [801/915], Loss: 71.0039, Accuracy: 50.00%\n",
      "Epoch [7/10], Step [901/915], Loss: 1533.4137, Accuracy: 40.62%\n",
      "Train Accuracy of the model on the train rna: 51.82361989403521 %\n",
      "Test Accuracy of the model on the test rna: 50.5708114779389 %\n",
      "Epoch [8/10], Step [1/915], Loss: 1179.0734, Accuracy: 59.38%\n",
      "Epoch [8/10], Step [101/915], Loss: 41.4624, Accuracy: 40.62%\n",
      "Epoch [8/10], Step [201/915], Loss: 94.8911, Accuracy: 56.25%\n",
      "Epoch [8/10], Step [301/915], Loss: 164.8700, Accuracy: 56.25%\n",
      "Epoch [8/10], Step [401/915], Loss: 360.9343, Accuracy: 53.12%\n",
      "Epoch [8/10], Step [501/915], Loss: 995.1186, Accuracy: 40.62%\n",
      "Epoch [8/10], Step [601/915], Loss: 18.4787, Accuracy: 50.00%\n",
      "Epoch [8/10], Step [701/915], Loss: 603.1223, Accuracy: 71.88%\n",
      "Epoch [8/10], Step [801/915], Loss: 218.8001, Accuracy: 62.50%\n",
      "Epoch [8/10], Step [901/915], Loss: 128.6824, Accuracy: 50.00%\n",
      "Train Accuracy of the model on the train rna: 51.82361989403521 %\n",
      "Test Accuracy of the model on the test rna: 50.5708114779389 %\n",
      "Epoch [9/10], Step [1/915], Loss: 51.5511, Accuracy: 65.62%\n",
      "Epoch [9/10], Step [101/915], Loss: 3227.3276, Accuracy: 56.25%\n",
      "Epoch [9/10], Step [201/915], Loss: 131.1648, Accuracy: 62.50%\n",
      "Epoch [9/10], Step [301/915], Loss: 2604.5830, Accuracy: 53.12%\n",
      "Epoch [9/10], Step [401/915], Loss: 773.2066, Accuracy: 56.25%\n",
      "Epoch [9/10], Step [501/915], Loss: 98.9918, Accuracy: 40.62%\n",
      "Epoch [9/10], Step [601/915], Loss: 19.2497, Accuracy: 53.12%\n",
      "Epoch [9/10], Step [701/915], Loss: 23.0729, Accuracy: 62.50%\n",
      "Epoch [9/10], Step [801/915], Loss: 217.4219, Accuracy: 40.62%\n",
      "Epoch [9/10], Step [901/915], Loss: 244.3272, Accuracy: 34.38%\n",
      "Train Accuracy of the model on the train rna: 48.176380105964796 %\n",
      "Test Accuracy of the model on the test rna: 49.42918852206109 %\n",
      "Epoch [10/10], Step [1/915], Loss: 94.0995, Accuracy: 37.50%\n",
      "Epoch [10/10], Step [101/915], Loss: 18.7710, Accuracy: 40.62%\n",
      "Epoch [10/10], Step [201/915], Loss: 43.2704, Accuracy: 53.12%\n",
      "Epoch [10/10], Step [301/915], Loss: 250.5784, Accuracy: 43.75%\n",
      "Epoch [10/10], Step [401/915], Loss: 8.7426, Accuracy: 46.88%\n",
      "Epoch [10/10], Step [501/915], Loss: 24.0675, Accuracy: 43.75%\n",
      "Epoch [10/10], Step [601/915], Loss: 20.2431, Accuracy: 65.62%\n",
      "Epoch [10/10], Step [701/915], Loss: 559.9044, Accuracy: 46.88%\n",
      "Epoch [10/10], Step [801/915], Loss: 256.1958, Accuracy: 50.00%\n",
      "Epoch [10/10], Step [901/915], Loss: 135.5487, Accuracy: 59.38%\n",
      "Train Accuracy of the model on the train rna: 48.176380105964796 %\n",
      "Test Accuracy of the model on the test rna: 49.42918852206109 %\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "train(cnntrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses[200:], label='Training loss')\n",
    "plt.plot(train_acc[200:], label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#plt.plot(train_acc[200:], label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-bd31bee9d1a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Save the model and plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMODEL_STORE_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'conv_net_model.ckpt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the model and plot\n",
    "torch.save(model.state_dict(), MODEL_STORE_PATH + 'conv_net_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
