{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# for reading and displaying images\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#Transformers\n",
    "from module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data set (small amount to test if it works first)\n",
    "\n",
    "xtrain = r\"data/training_sample_NoSparse.csv.gz\"\n",
    "ytrain = r\"data/training_label_NoSparse.csv.gz\"\n",
    "xtest = r\"data/testing_sample_NoSparse.csv.gz\"\n",
    "ytest = r\"data/testing_label_NoSparse.csv.gz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15161, 14094)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check balance\n",
    "samplesdf = pd.DataFrame()\n",
    "for df in  pd.read_csv(ytrain,compression =\"gzip\",delimiter=',', chunksize = 10000, header=0):\n",
    "    samplesdf = samplesdf.append(df)\n",
    "y_train = samplesdf.to_numpy()\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "for x in y_train:\n",
    "    if x == 0:\n",
    "        num0 = num0 + 1\n",
    "    else:\n",
    "        num1 = num1 + 1\n",
    "num0,num1 #checking if it is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.   ... 3.11 0.   3.69]\n",
      " [0.   0.   0.   ... 3.16 0.   3.33]\n",
      " [0.   0.   0.   ... 2.98 0.   3.64]\n",
      " ...\n",
      " [1.39 0.   0.   ... 1.95 0.   3.57]\n",
      " [0.   2.08 0.   ... 2.71 0.   3.09]\n",
      " [0.   0.   0.   ... 3.12 0.   2.85]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(xtrain,compression =\"gzip\",delimiter=',', nrows=123, header=0)\n",
    "x_train = df.to_numpy()\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self,samples,labels,numrows):\n",
    "\n",
    "        self.data = pd.read_csv(samples,compression =\"gzip\",delimiter=',', nrows = numrows, header=0)\n",
    "        self.label = pd.read_csv(labels,compression =\"gzip\",delimiter=',', nrows = numrows, header=0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        rna = self.data.iloc[idx]\n",
    "        seplb = self.label.iloc[idx]\n",
    "        rna = np.array([rna])\n",
    "        seplb = np.array([seplb])\n",
    "        rna = rna.astype('double').reshape(-1,3273)\n",
    "        i = 0\n",
    "        d = np.zeros((len(seplb),2))\n",
    "        for x in seplb:\n",
    "            if x == 0:\n",
    "                d[i] = [1,0]\n",
    "            else:\n",
    "                d[i] = [0,1]\n",
    "        sample = {'rna': rna, 'label': d}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(samples=xtrain,labels=ytrain,numrows = 29255)\n",
    "test_dataset = Dataset(samples = xtest,labels = ytest,numrows = 3241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 20             # train the training data n times, to save time, we just train 1 epoch\n",
    "LR = 0.0001              # learning rate\n",
    "batch_size = 32\n",
    "wd = LR / EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (x,1, 8949)\n",
    "            nn.Conv1d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=4,            # n_filters\n",
    "                kernel_size=3,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=1,                  # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (x,64,8949)\n",
    "            nn.BatchNorm1d(4),\n",
    "            nn.ReLU(),                      # activation\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (x,64, 8949)\n",
    "            nn.Conv1d(4,4,3,1,1),            \n",
    "            nn.ReLU(),  \n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.MaxPool1d(kernel_size =2, stride=2,ceil_mode = True),                # output shape (x,64,4478)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         # input shape (x,64,4478)\n",
    "            nn.Conv1d(4, 4, 3, 1, 1),     # output shape (x,128,4478)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool1d(kernel_size =2, stride=2,ceil_mode = True),                # output shape (x,128,2238)\n",
    "        )\n",
    "        self.out = nn.Linear(3276 , 2)   # fully connected layer, output 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cnn = CNN()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()                       # the target label is not one-hotted\n",
    "if torch.cuda.is_available():\n",
    "    cnn = cnn.cuda()\n",
    "    loss_func = loss_func.cuda()\n",
    "cnn = cnn.double()    \n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetTransformer(nn.Module):\n",
    "    def __init__(self, dim_input, num_outputs, dim_output,\n",
    "            num_inds=32, dim_hidden=128, num_heads=2, ln=False):\n",
    "        super(SetTransformer, self).__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "                ISAB(dim_input, dim_hidden, num_heads, num_inds, ln=ln),\n",
    "                ISAB(dim_hidden, dim_hidden, num_heads, num_inds, ln=ln))\n",
    "        self.dec = nn.Sequential(\n",
    "                PMA(dim_hidden, num_heads, num_outputs, ln=ln),\n",
    "                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
    "                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),\n",
    "                nn.Linear(dim_hidden, dim_output))\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dec(self.enc(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SetTransformer(\n",
      "  (enc): Sequential(\n",
      "    (0): ISAB(\n",
      "      (mab0): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=3273, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=3273, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (mab1): MAB(\n",
      "        (fc_q): Linear(in_features=3273, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ISAB(\n",
      "      (mab0): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (mab1): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dec): Sequential(\n",
      "    (0): PMA(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): SAB(\n",
      "      (mab): MAB(\n",
      "        (fc_q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_k): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_v): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (fc_o): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trans = SetTransformer(3273,2,1)\n",
    "optimizer = torch.optim.Adam(trans.parameters(), lr=LR)   \n",
    "loss_func = nn.L1Loss()                      \n",
    "if torch.cuda.is_available():\n",
    "    loss_func = loss_func.cuda()\n",
    "    trans = trans.cuda()\n",
    "trans = trans.double()\n",
    "print(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Trans(nn.Module):\n",
    "    def __init__(self, dim_input, num_outputs, dim_output,\n",
    "            num_inds=32, dim_hidden=128, num_heads=4, ln=False):\n",
    "        super(CNN_Trans, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (x,1, 8949)\n",
    "            nn.Conv1d(\n",
    "                in_channels=1,              # input height\n",
    "                out_channels=4,            # n_filters\n",
    "                kernel_size=3,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=1,                  # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (x,64,8949)\n",
    "            nn.BatchNorm1d(4),\n",
    "            nn.ReLU(),                      # activation\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (x,64, 8949)\n",
    "            nn.Conv1d(4,4,3,1,1),            \n",
    "            nn.ReLU(),  \n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.MaxPool1d(kernel_size =2, stride=2,ceil_mode = True),                # output shape (x,64,4478)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         # input shape (x,64,4478)\n",
    "            nn.Conv1d(4, 8, 3, 1, 1),     # output shape (x,128,4478)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool1d(kernel_size =2, stride=2,ceil_mode = True),                # output shape (x,128,2238)\n",
    "        )\n",
    "        self.enc = nn.Sequential(\n",
    "            SAB(dim_in=1, dim_out=64, num_heads=4),\n",
    "            SAB(dim_in=64, dim_out=64, num_heads=4),\n",
    "        )\n",
    "        self.dec = nn.Sequential(\n",
    "            PMA(dim=64, num_heads=4, num_seeds=1),\n",
    "            nn.Linear(in_features=64, out_features=2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = x.reshape(-1,6552,1)\n",
    "        return self.dec(self.enc(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cnntrans = CNN_Trans(3276,1,2)\n",
    "optimizer = torch.optim.Adam(cnntrans.parameters(), lr=LR)   \n",
    "loss_func = nn.L1Loss()                      \n",
    "if torch.cuda.is_available():\n",
    "    loss_func = loss_func.cuda()\n",
    "    cnntrans = cnntrans.cuda()\n",
    "cnntrans = cnntrans.double()\n",
    "print(cnntrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallSetTransformer(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "            SAB(dim_in=1, dim_out=64, num_heads=4),\n",
    "            SAB(dim_in=64, dim_out=64, num_heads=4),\n",
    "        )\n",
    "        self.dec = nn.Sequential(\n",
    "            PMA(dim=64, num_heads=4, num_seeds=1),\n",
    "            nn.Linear(in_features=64, out_features=2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        x = self.dec(x)\n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smalltrans = SmallSetTransformer()\n",
    "optimizer = torch.optim.Adam(smalltrans.parameters(), lr=LR)   \n",
    "loss_func = nn.L1Loss()                      \n",
    "if torch.cuda.is_available():\n",
    "    loss_func = loss_func.cuda()\n",
    "    smalltrans = smalltrans.cuda()\n",
    "smalltrans = smalltrans.double()\n",
    "print(smalltrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in train_loader:\n",
    "            rna,labels = batch[\"rna\"], batch[\"label\"] \n",
    "            if torch.cuda.is_available():\n",
    "                rna = rna.cuda()\n",
    "                labels = labels.cuda()\n",
    "            labels = labels.reshape(-1,2)\n",
    "            outputs = model(rna)\n",
    "            outputs = outputs.reshape(-1,2)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, labels = torch.max(labels.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "           # print(total,correct)\n",
    "\n",
    "        print('Train Accuracy of the model on the train rna: {} %'.format((correct / total) * 100))\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in test_loader:\n",
    "            rna,labels = batch[\"rna\"], batch[\"label\"] \n",
    "            if torch.cuda.is_available():\n",
    "                rna = rna.cuda()\n",
    "                labels = labels.cuda()\n",
    "            labels = labels.reshape(-1,2)\n",
    "            outputs = model(rna)\n",
    "            outputs = outputs.reshape(-1,2)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, labels = torch.max(labels.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    #print(total,correct)\n",
    "\n",
    "        print('Test Accuracy of the model on the test rna: {} %'.format((correct / total) * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train(model): \n",
    "    total_step = len(train_loader)\n",
    "    num_epoch = EPOCH\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            # Run the forward pass\n",
    "            rna,labels = batch[\"rna\"], batch[\"label\"] \n",
    "            if torch.cuda.is_available():\n",
    "                rna = rna.cuda()\n",
    "                labels = labels.cuda()\n",
    "            outputs = model(rna)\n",
    "            labels = labels.long()\n",
    "            #print(outputs)\n",
    "            outputs = outputs.reshape(-1,2)\n",
    "            labels = labels.reshape(-1,2)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            # Backprop and perform Adam optimisation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track the accuracy\n",
    "            total = labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, labels = torch.max(labels.data, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            train_acc.append(correct / total)\n",
    "            if i % 100 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                        .format(epoch + 1, num_epoch , i + 1, total_step, loss.item(),\n",
    "                                (correct / total) * 100))\n",
    "        test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [1/915], Loss: 0.5073, Accuracy: 59.38%\n",
      "Epoch [1/20], Step [101/915], Loss: 0.4924, Accuracy: 53.12%\n",
      "Epoch [1/20], Step [201/915], Loss: 0.4966, Accuracy: 43.75%\n",
      "Epoch [1/20], Step [301/915], Loss: 0.2211, Accuracy: 78.12%\n",
      "Epoch [1/20], Step [401/915], Loss: 0.3241, Accuracy: 68.75%\n",
      "Epoch [1/20], Step [501/915], Loss: 0.2573, Accuracy: 75.00%\n",
      "Epoch [1/20], Step [601/915], Loss: 0.2688, Accuracy: 78.12%\n",
      "Epoch [1/20], Step [701/915], Loss: 0.2377, Accuracy: 81.25%\n",
      "Epoch [1/20], Step [801/915], Loss: 0.1908, Accuracy: 87.50%\n",
      "Epoch [1/20], Step [901/915], Loss: 0.2896, Accuracy: 71.88%\n",
      "Train Accuracy of the model on the train rna: 81.31601435652026 %\n",
      "Test Accuracy of the model on the test rna: 78.64856525763653 %\n",
      "Epoch [2/20], Step [1/915], Loss: 0.1956, Accuracy: 84.38%\n",
      "Epoch [2/20], Step [101/915], Loss: 0.2024, Accuracy: 81.25%\n",
      "Epoch [2/20], Step [201/915], Loss: 0.1489, Accuracy: 87.50%\n",
      "Epoch [2/20], Step [301/915], Loss: 0.1525, Accuracy: 87.50%\n",
      "Epoch [2/20], Step [401/915], Loss: 0.2111, Accuracy: 81.25%\n",
      "Epoch [2/20], Step [501/915], Loss: 0.2197, Accuracy: 78.12%\n",
      "Epoch [2/20], Step [601/915], Loss: 0.1588, Accuracy: 87.50%\n",
      "Epoch [2/20], Step [701/915], Loss: 0.1231, Accuracy: 90.62%\n",
      "Epoch [2/20], Step [801/915], Loss: 0.1642, Accuracy: 84.38%\n",
      "Epoch [2/20], Step [901/915], Loss: 0.1998, Accuracy: 84.38%\n",
      "Train Accuracy of the model on the train rna: 84.33088360963937 %\n",
      "Test Accuracy of the model on the test rna: 79.60506016661523 %\n",
      "Epoch [3/20], Step [1/915], Loss: 0.1986, Accuracy: 84.38%\n",
      "Epoch [3/20], Step [101/915], Loss: 0.1383, Accuracy: 87.50%\n",
      "Epoch [3/20], Step [201/915], Loss: 0.1621, Accuracy: 87.50%\n",
      "Epoch [3/20], Step [301/915], Loss: 0.1622, Accuracy: 87.50%\n",
      "Epoch [3/20], Step [401/915], Loss: 0.1294, Accuracy: 87.50%\n",
      "Epoch [3/20], Step [501/915], Loss: 0.1695, Accuracy: 81.25%\n",
      "Epoch [3/20], Step [601/915], Loss: 0.2464, Accuracy: 75.00%\n",
      "Epoch [3/20], Step [701/915], Loss: 0.1569, Accuracy: 87.50%\n",
      "Epoch [3/20], Step [801/915], Loss: 0.0808, Accuracy: 93.75%\n",
      "Epoch [3/20], Step [901/915], Loss: 0.1963, Accuracy: 84.38%\n",
      "Train Accuracy of the model on the train rna: 83.20628952315843 %\n",
      "Test Accuracy of the model on the test rna: 78.37087318728787 %\n",
      "Epoch [4/20], Step [1/915], Loss: 0.1383, Accuracy: 84.38%\n",
      "Epoch [4/20], Step [101/915], Loss: 0.1105, Accuracy: 90.62%\n",
      "Epoch [4/20], Step [201/915], Loss: 0.2283, Accuracy: 78.12%\n",
      "Epoch [4/20], Step [301/915], Loss: 0.1824, Accuracy: 84.38%\n",
      "Epoch [4/20], Step [401/915], Loss: 0.2690, Accuracy: 78.12%\n",
      "Epoch [4/20], Step [501/915], Loss: 0.2135, Accuracy: 78.12%\n",
      "Epoch [4/20], Step [601/915], Loss: 0.1452, Accuracy: 84.38%\n",
      "Epoch [4/20], Step [701/915], Loss: 0.1590, Accuracy: 84.38%\n",
      "Epoch [4/20], Step [801/915], Loss: 0.1896, Accuracy: 81.25%\n",
      "Epoch [4/20], Step [901/915], Loss: 0.2817, Accuracy: 71.88%\n",
      "Train Accuracy of the model on the train rna: 84.09502649119808 %\n",
      "Test Accuracy of the model on the test rna: 79.66676951558162 %\n",
      "Epoch [5/20], Step [1/915], Loss: 0.1986, Accuracy: 84.38%\n",
      "Epoch [5/20], Step [101/915], Loss: 0.1064, Accuracy: 90.62%\n",
      "Epoch [5/20], Step [201/915], Loss: 0.1798, Accuracy: 84.38%\n",
      "Epoch [5/20], Step [301/915], Loss: 0.0381, Accuracy: 100.00%\n",
      "Epoch [5/20], Step [401/915], Loss: 0.1804, Accuracy: 81.25%\n",
      "Epoch [5/20], Step [501/915], Loss: 0.1241, Accuracy: 90.62%\n",
      "Epoch [5/20], Step [601/915], Loss: 0.1467, Accuracy: 87.50%\n",
      "Epoch [5/20], Step [701/915], Loss: 0.1158, Accuracy: 90.62%\n",
      "Epoch [5/20], Step [801/915], Loss: 0.1404, Accuracy: 87.50%\n",
      "Epoch [5/20], Step [901/915], Loss: 0.0897, Accuracy: 93.75%\n",
      "Train Accuracy of the model on the train rna: 89.60861391215177 %\n",
      "Test Accuracy of the model on the test rna: 83.09163838321506 %\n",
      "Epoch [6/20], Step [1/915], Loss: 0.1219, Accuracy: 90.62%\n",
      "Epoch [6/20], Step [101/915], Loss: 0.1382, Accuracy: 87.50%\n",
      "Epoch [6/20], Step [201/915], Loss: 0.0840, Accuracy: 93.75%\n",
      "Epoch [6/20], Step [301/915], Loss: 0.1252, Accuracy: 87.50%\n",
      "Epoch [6/20], Step [401/915], Loss: 0.2475, Accuracy: 75.00%\n",
      "Epoch [6/20], Step [501/915], Loss: 0.2152, Accuracy: 78.12%\n",
      "Epoch [6/20], Step [601/915], Loss: 0.2394, Accuracy: 75.00%\n",
      "Epoch [6/20], Step [701/915], Loss: 0.1347, Accuracy: 84.38%\n",
      "Epoch [6/20], Step [801/915], Loss: 0.0460, Accuracy: 96.88%\n",
      "Epoch [6/20], Step [901/915], Loss: 0.1789, Accuracy: 87.50%\n",
      "Train Accuracy of the model on the train rna: 88.35754571868057 %\n",
      "Test Accuracy of the model on the test rna: 81.73403270595495 %\n",
      "Epoch [7/20], Step [1/915], Loss: 0.1449, Accuracy: 87.50%\n",
      "Epoch [7/20], Step [101/915], Loss: 0.1228, Accuracy: 87.50%\n",
      "Epoch [7/20], Step [201/915], Loss: 0.1814, Accuracy: 81.25%\n",
      "Epoch [7/20], Step [301/915], Loss: 0.0875, Accuracy: 90.62%\n",
      "Epoch [7/20], Step [401/915], Loss: 0.0557, Accuracy: 96.88%\n",
      "Epoch [7/20], Step [501/915], Loss: 0.0567, Accuracy: 96.88%\n",
      "Epoch [7/20], Step [601/915], Loss: 0.1658, Accuracy: 87.50%\n",
      "Epoch [7/20], Step [701/915], Loss: 0.1118, Accuracy: 90.62%\n",
      "Epoch [7/20], Step [801/915], Loss: 0.0867, Accuracy: 90.62%\n",
      "Epoch [7/20], Step [901/915], Loss: 0.1963, Accuracy: 78.12%\n",
      "Train Accuracy of the model on the train rna: 90.43924115535806 %\n",
      "Test Accuracy of the model on the test rna: 83.21505708114779 %\n",
      "Epoch [8/20], Step [1/915], Loss: 0.1059, Accuracy: 90.62%\n",
      "Epoch [8/20], Step [101/915], Loss: 0.0596, Accuracy: 96.88%\n",
      "Epoch [8/20], Step [201/915], Loss: 0.0887, Accuracy: 90.62%\n",
      "Epoch [8/20], Step [301/915], Loss: 0.2211, Accuracy: 78.12%\n",
      "Epoch [8/20], Step [401/915], Loss: 0.1029, Accuracy: 90.62%\n",
      "Epoch [8/20], Step [501/915], Loss: 0.0647, Accuracy: 93.75%\n",
      "Epoch [8/20], Step [601/915], Loss: 0.1645, Accuracy: 84.38%\n",
      "Epoch [8/20], Step [701/915], Loss: 0.2099, Accuracy: 78.12%\n",
      "Epoch [8/20], Step [801/915], Loss: 0.0929, Accuracy: 93.75%\n",
      "Epoch [8/20], Step [901/915], Loss: 0.1007, Accuracy: 90.62%\n",
      "Train Accuracy of the model on the train rna: 92.29875235002564 %\n",
      "Test Accuracy of the model on the test rna: 83.9864239432274 %\n",
      "Epoch [9/20], Step [1/915], Loss: 0.0741, Accuracy: 93.75%\n",
      "Epoch [9/20], Step [101/915], Loss: 0.0382, Accuracy: 96.88%\n",
      "Epoch [9/20], Step [201/915], Loss: 0.0735, Accuracy: 93.75%\n",
      "Epoch [9/20], Step [301/915], Loss: 0.1018, Accuracy: 90.62%\n",
      "Epoch [9/20], Step [401/915], Loss: 0.1098, Accuracy: 90.62%\n",
      "Epoch [9/20], Step [501/915], Loss: 0.0988, Accuracy: 90.62%\n",
      "Epoch [9/20], Step [601/915], Loss: 0.0728, Accuracy: 93.75%\n",
      "Epoch [9/20], Step [701/915], Loss: 0.0688, Accuracy: 93.75%\n",
      "Epoch [9/20], Step [801/915], Loss: 0.0785, Accuracy: 93.75%\n",
      "Epoch [9/20], Step [901/915], Loss: 0.0085, Accuracy: 100.00%\n",
      "Train Accuracy of the model on the train rna: 92.96188685694753 %\n",
      "Test Accuracy of the model on the test rna: 84.48009873495835 %\n",
      "Epoch [10/20], Step [1/915], Loss: 0.0758, Accuracy: 93.75%\n",
      "Epoch [10/20], Step [101/915], Loss: 0.0734, Accuracy: 93.75%\n",
      "Epoch [10/20], Step [201/915], Loss: 0.1338, Accuracy: 87.50%\n",
      "Epoch [10/20], Step [301/915], Loss: 0.0928, Accuracy: 90.62%\n",
      "Epoch [10/20], Step [401/915], Loss: 0.0647, Accuracy: 93.75%\n",
      "Epoch [10/20], Step [501/915], Loss: 0.1345, Accuracy: 87.50%\n",
      "Epoch [10/20], Step [601/915], Loss: 0.1872, Accuracy: 81.25%\n",
      "Epoch [10/20], Step [701/915], Loss: 0.0599, Accuracy: 93.75%\n",
      "Epoch [10/20], Step [801/915], Loss: 0.1176, Accuracy: 87.50%\n",
      "Epoch [10/20], Step [901/915], Loss: 0.0908, Accuracy: 90.62%\n",
      "Train Accuracy of the model on the train rna: 91.55358058451547 %\n",
      "Test Accuracy of the model on the test rna: 83.92471459426103 %\n",
      "Epoch [11/20], Step [1/915], Loss: 0.0531, Accuracy: 96.88%\n",
      "Epoch [11/20], Step [101/915], Loss: 0.1387, Accuracy: 84.38%\n",
      "Epoch [11/20], Step [201/915], Loss: 0.0600, Accuracy: 96.88%\n",
      "Epoch [11/20], Step [301/915], Loss: 0.1344, Accuracy: 87.50%\n",
      "Epoch [11/20], Step [401/915], Loss: 0.0094, Accuracy: 100.00%\n",
      "Epoch [11/20], Step [501/915], Loss: 0.0044, Accuracy: 100.00%\n",
      "Epoch [11/20], Step [601/915], Loss: 0.1139, Accuracy: 87.50%\n",
      "Epoch [11/20], Step [701/915], Loss: 0.1617, Accuracy: 84.38%\n",
      "Epoch [11/20], Step [801/915], Loss: 0.0353, Accuracy: 96.88%\n",
      "Epoch [11/20], Step [901/915], Loss: 0.0848, Accuracy: 93.75%\n",
      "Train Accuracy of the model on the train rna: 91.41001538198599 %\n",
      "Test Accuracy of the model on the test rna: 83.36933045356372 %\n",
      "Epoch [12/20], Step [1/915], Loss: 0.1263, Accuracy: 87.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Step [101/915], Loss: 0.1351, Accuracy: 87.50%\n",
      "Epoch [12/20], Step [201/915], Loss: 0.1714, Accuracy: 84.38%\n",
      "Epoch [12/20], Step [301/915], Loss: 0.1324, Accuracy: 87.50%\n",
      "Epoch [12/20], Step [401/915], Loss: 0.0386, Accuracy: 96.88%\n",
      "Epoch [12/20], Step [501/915], Loss: 0.0070, Accuracy: 100.00%\n",
      "Epoch [12/20], Step [601/915], Loss: 0.0660, Accuracy: 93.75%\n",
      "Epoch [12/20], Step [701/915], Loss: 0.0352, Accuracy: 96.88%\n",
      "Epoch [12/20], Step [801/915], Loss: 0.0731, Accuracy: 93.75%\n",
      "Epoch [12/20], Step [901/915], Loss: 0.0685, Accuracy: 93.75%\n",
      "Train Accuracy of the model on the train rna: 94.24371902238934 %\n",
      "Test Accuracy of the model on the test rna: 85.65257636531935 %\n",
      "Epoch [13/20], Step [1/915], Loss: 0.0488, Accuracy: 96.88%\n",
      "Epoch [13/20], Step [101/915], Loss: 0.0977, Accuracy: 90.62%\n",
      "Epoch [13/20], Step [201/915], Loss: 0.1302, Accuracy: 87.50%\n",
      "Epoch [13/20], Step [301/915], Loss: 0.0177, Accuracy: 100.00%\n",
      "Epoch [13/20], Step [401/915], Loss: 0.0693, Accuracy: 93.75%\n",
      "Epoch [13/20], Step [501/915], Loss: 0.0956, Accuracy: 90.62%\n",
      "Epoch [13/20], Step [601/915], Loss: 0.0920, Accuracy: 90.62%\n",
      "Epoch [13/20], Step [701/915], Loss: 0.0382, Accuracy: 96.88%\n",
      "Epoch [13/20], Step [801/915], Loss: 0.0456, Accuracy: 96.88%\n",
      "Epoch [13/20], Step [901/915], Loss: 0.1347, Accuracy: 87.50%\n",
      "Train Accuracy of the model on the train rna: 92.62006494616305 %\n",
      "Test Accuracy of the model on the test rna: 83.49274915149645 %\n",
      "Epoch [14/20], Step [1/915], Loss: 0.0979, Accuracy: 90.62%\n",
      "Epoch [14/20], Step [101/915], Loss: 0.0653, Accuracy: 93.75%\n",
      "Epoch [14/20], Step [201/915], Loss: 0.0649, Accuracy: 93.75%\n",
      "Epoch [14/20], Step [301/915], Loss: 0.1244, Accuracy: 87.50%\n",
      "Epoch [14/20], Step [401/915], Loss: 0.0358, Accuracy: 96.88%\n",
      "Epoch [14/20], Step [501/915], Loss: 0.2393, Accuracy: 75.00%\n",
      "Epoch [14/20], Step [601/915], Loss: 0.0917, Accuracy: 93.75%\n",
      "Epoch [14/20], Step [701/915], Loss: 0.0337, Accuracy: 96.88%\n",
      "Epoch [14/20], Step [801/915], Loss: 0.1224, Accuracy: 87.50%\n",
      "Epoch [14/20], Step [901/915], Loss: 0.0670, Accuracy: 93.75%\n",
      "Train Accuracy of the model on the train rna: 92.66450179456504 %\n",
      "Test Accuracy of the model on the test rna: 83.46189447701326 %\n",
      "Epoch [15/20], Step [1/915], Loss: 0.1359, Accuracy: 87.50%\n",
      "Epoch [15/20], Step [101/915], Loss: 0.1290, Accuracy: 87.50%\n",
      "Epoch [15/20], Step [201/915], Loss: 0.0985, Accuracy: 90.62%\n",
      "Epoch [15/20], Step [301/915], Loss: 0.0947, Accuracy: 90.62%\n",
      "Epoch [15/20], Step [401/915], Loss: 0.1345, Accuracy: 87.50%\n",
      "Epoch [15/20], Step [501/915], Loss: 0.0160, Accuracy: 100.00%\n",
      "Epoch [15/20], Step [601/915], Loss: 0.2073, Accuracy: 81.25%\n",
      "Epoch [15/20], Step [701/915], Loss: 0.0399, Accuracy: 96.88%\n",
      "Epoch [15/20], Step [801/915], Loss: 0.0332, Accuracy: 96.88%\n",
      "Epoch [15/20], Step [901/915], Loss: 0.1002, Accuracy: 90.62%\n",
      "Train Accuracy of the model on the train rna: 93.94975217911468 %\n",
      "Test Accuracy of the model on the test rna: 85.1589015735884 %\n",
      "Epoch [16/20], Step [1/915], Loss: 0.0691, Accuracy: 93.75%\n",
      "Epoch [16/20], Step [101/915], Loss: 0.0058, Accuracy: 100.00%\n",
      "Epoch [16/20], Step [201/915], Loss: 0.1003, Accuracy: 90.62%\n",
      "Epoch [16/20], Step [301/915], Loss: 0.0404, Accuracy: 96.88%\n",
      "Epoch [16/20], Step [401/915], Loss: 0.0362, Accuracy: 96.88%\n",
      "Epoch [16/20], Step [501/915], Loss: 0.0734, Accuracy: 96.88%\n",
      "Epoch [16/20], Step [601/915], Loss: 0.1278, Accuracy: 87.50%\n",
      "Epoch [16/20], Step [701/915], Loss: 0.0310, Accuracy: 96.88%\n",
      "Epoch [16/20], Step [801/915], Loss: 0.0534, Accuracy: 93.75%\n",
      "Epoch [16/20], Step [901/915], Loss: 0.0677, Accuracy: 93.75%\n",
      "Train Accuracy of the model on the train rna: 94.58895915228166 %\n",
      "Test Accuracy of the model on the test rna: 85.09719222462203 %\n",
      "Epoch [17/20], Step [1/915], Loss: 0.0443, Accuracy: 96.88%\n",
      "Epoch [17/20], Step [101/915], Loss: 0.0070, Accuracy: 100.00%\n",
      "Epoch [17/20], Step [201/915], Loss: 0.0962, Accuracy: 90.62%\n",
      "Epoch [17/20], Step [301/915], Loss: 0.0722, Accuracy: 93.75%\n",
      "Epoch [17/20], Step [401/915], Loss: 0.0948, Accuracy: 90.62%\n",
      "Epoch [17/20], Step [501/915], Loss: 0.0341, Accuracy: 96.88%\n",
      "Epoch [17/20], Step [601/915], Loss: 0.0375, Accuracy: 96.88%\n",
      "Epoch [17/20], Step [701/915], Loss: 0.1275, Accuracy: 87.50%\n",
      "Epoch [17/20], Step [801/915], Loss: 0.1486, Accuracy: 84.38%\n",
      "Epoch [17/20], Step [901/915], Loss: 0.0053, Accuracy: 100.00%\n",
      "Train Accuracy of the model on the train rna: 94.31891984276191 %\n",
      "Test Accuracy of the model on the test rna: 85.3440296204875 %\n",
      "Epoch [18/20], Step [1/915], Loss: 0.0034, Accuracy: 100.00%\n",
      "Epoch [18/20], Step [101/915], Loss: 0.0662, Accuracy: 93.75%\n",
      "Epoch [18/20], Step [201/915], Loss: 0.0647, Accuracy: 96.88%\n",
      "Epoch [18/20], Step [301/915], Loss: 0.0187, Accuracy: 96.88%\n",
      "Epoch [18/20], Step [401/915], Loss: 0.0350, Accuracy: 96.88%\n",
      "Epoch [18/20], Step [501/915], Loss: 0.0658, Accuracy: 93.75%\n",
      "Epoch [18/20], Step [601/915], Loss: 0.0274, Accuracy: 96.88%\n",
      "Epoch [18/20], Step [701/915], Loss: 0.0029, Accuracy: 100.00%\n",
      "Epoch [18/20], Step [801/915], Loss: 0.0477, Accuracy: 96.88%\n",
      "Epoch [18/20], Step [901/915], Loss: 0.0350, Accuracy: 96.88%\n",
      "Train Accuracy of the model on the train rna: 95.26918475474278 %\n",
      "Test Accuracy of the model on the test rna: 86.23881518049986 %\n",
      "Epoch [19/20], Step [1/915], Loss: 0.0349, Accuracy: 96.88%\n",
      "Epoch [19/20], Step [101/915], Loss: 0.1577, Accuracy: 84.38%\n",
      "Epoch [19/20], Step [201/915], Loss: 0.0341, Accuracy: 96.88%\n",
      "Epoch [19/20], Step [301/915], Loss: 0.1009, Accuracy: 90.62%\n",
      "Epoch [19/20], Step [401/915], Loss: 0.0694, Accuracy: 93.75%\n",
      "Epoch [19/20], Step [501/915], Loss: 0.0179, Accuracy: 100.00%\n",
      "Epoch [19/20], Step [601/915], Loss: 0.0968, Accuracy: 90.62%\n",
      "Epoch [19/20], Step [701/915], Loss: 0.1895, Accuracy: 81.25%\n",
      "Epoch [19/20], Step [801/915], Loss: 0.0658, Accuracy: 93.75%\n",
      "Epoch [19/20], Step [901/915], Loss: 0.1662, Accuracy: 84.38%\n",
      "Train Accuracy of the model on the train rna: 93.83353272944795 %\n",
      "Test Accuracy of the model on the test rna: 84.69608145634064 %\n",
      "Epoch [20/20], Step [1/915], Loss: 0.0342, Accuracy: 96.88%\n",
      "Epoch [20/20], Step [101/915], Loss: 0.1543, Accuracy: 84.38%\n",
      "Epoch [20/20], Step [201/915], Loss: 0.0320, Accuracy: 96.88%\n",
      "Epoch [20/20], Step [301/915], Loss: 0.0357, Accuracy: 96.88%\n",
      "Epoch [20/20], Step [401/915], Loss: 0.1267, Accuracy: 87.50%\n",
      "Epoch [20/20], Step [501/915], Loss: 0.1283, Accuracy: 87.50%\n",
      "Epoch [20/20], Step [601/915], Loss: 0.0658, Accuracy: 93.75%\n",
      "Epoch [20/20], Step [701/915], Loss: 0.0969, Accuracy: 90.62%\n",
      "Epoch [20/20], Step [801/915], Loss: 0.0967, Accuracy: 90.62%\n",
      "Epoch [20/20], Step [901/915], Loss: 0.1277, Accuracy: 87.50%\n",
      "Train Accuracy of the model on the train rna: 94.27106477525209 %\n",
      "Test Accuracy of the model on the test rna: 84.29497068805925 %\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "train(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(train_acc, label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAN4ElEQVR4nO3cf6jdd33H8efLJl1YjXUkV5DcaDKWTkM3sLt0HcLsqBtp/0j+cEgCxSmlAbfKmEXocFSpfzmZAyGbRlacgq3VP+SCkfzhKgUxkls6S5NSuYuduVXoNXb9p6Rttvf+OKfe4+1Nz7f3fu896f08HxC43+/53HPefLh53nPPr1QVkqTN702THkCStDEMviQ1wuBLUiMMviQ1wuBLUiMMviQ1Ymzwk9yf5NkkT1zm8iT5QpL5JI8nuaH/MSVJa9XlHv5XgAOvcfmtwL7hv6PAv659LElS38YGv6oeAX71GksOAV+tgVPAW5O8va8BJUn92NLDdewCzo8cLwzP/WL5wiRHGfwVwDXXXPNH73rXu3q4eUlqx6OPPvrLqppazff2EfzOquo4cBxgZmam5ubmNvLmJekNL8l/r/Z7+3iVzjPA7pHj6eE5SdIVpI/gzwIfGr5a5ybg+ap61cM5kqTJGvuQTpIHgJuBnUkWgE8BWwGq6ovACeA2YB54AfjIeg0rSVq9scGvqiNjLi/gb3qbSJIa8fLLL7OwsMDFixdfddm2bduYnp5m69atvd3ehj5pK0lasrCwwPbt29mzZw9Jfn2+qrhw4QILCwvs3bu3t9vzoxUkaUIuXrzIjh07fiP2AEnYsWPHivf818LgS9IELY/9uPNrYfAlqREGX5IaYfAlaYIGL3Tsfn4tDL4kTci2bdu4cOHCq+L+yqt0tm3b1uvt+bJMSZqQ6elpFhYWWFxcfNVlr7wOv08GX5ImZOvWrb2+zn4cH9KRpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqhMGXpEYYfElqRKfgJzmQ5Kkk80nuWeHydyR5OMljSR5Pclv/o0qS1mJs8JNcBRwDbgX2A0eS7F+27B+Ah6rqPcBh4F/6HlSStDZd7uHfCMxX1bmqegl4EDi0bE0Bbxl+fS3w8/5GlCT1oUvwdwHnR44XhudGfRq4PckCcAL42EpXlORokrkkc4uLi6sYV5K0Wn09aXsE+EpVTQO3AV9L8qrrrqrjVTVTVTNTU1M93bQkqYsuwX8G2D1yPD08N+oO4CGAqvohsA3Y2ceAkqR+dAn+aWBfkr1JrmbwpOzssjU/A24BSPJuBsH3MRtJuoKMDX5VXQLuAk4CTzJ4Nc6ZJPclOThcdjdwZ5IfAw8AH66qWq+hJUmv35Yui6rqBIMnY0fP3Tvy9Vngvf2OJknqk++0laRGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJaoTBl6RGGHxJakSn4Cc5kOSpJPNJ7rnMmg8mOZvkTJKv9zumJGmttoxbkOQq4Bjw58ACcDrJbFWdHVmzD/h74L1V9VySt63XwJKk1elyD/9GYL6qzlXVS8CDwKFla+4EjlXVcwBV9Wy/Y0qS1qpL8HcB50eOF4bnRl0HXJfkB0lOJTmw0hUlOZpkLsnc4uLi6iaWJK1KX0/abgH2ATcDR4AvJ3nr8kVVdbyqZqpqZmpqqqebliR10SX4zwC7R46nh+dGLQCzVfVyVf0U+AmDXwCSpCtEl+CfBvYl2ZvkauAwMLtszbcZ3LsnyU4GD/Gc629MSdJajQ1+VV0C7gJOAk8CD1XVmST3JTk4XHYSuJDkLPAw8ImqurBeQ0uSXr9U1URueGZmpubm5iZy25L0RpXk0aqaWc33+k5bSWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWqEwZekRhh8SWpEp+AnOZDkqSTzSe55jXUfSFJJZvobUZLUh7HBT3IVcAy4FdgPHEmyf4V124G/BX7U95CSpLXrcg//RmC+qs5V1UvAg8ChFdZ9BvgscLHH+SRJPekS/F3A+ZHjheG5X0tyA7C7qr7zWleU5GiSuSRzi4uLr3tYSdLqrflJ2yRvAj4P3D1ubVUdr6qZqpqZmppa601Lkl6HLsF/Btg9cjw9PPeK7cD1wPeTPA3cBMz6xK0kXVm6BP80sC/J3iRXA4eB2VcurKrnq2pnVe2pqj3AKeBgVc2ty8SSpFUZG/yqugTcBZwEngQeqqozSe5LcnC9B5Qk9WNLl0VVdQI4sezcvZdZe/Pax5Ik9c132kpSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDXC4EtSIwy+JDWiU/CTHEjyVJL5JPescPnHk5xN8niS7yV5Z/+jSpLWYmzwk1wFHANuBfYDR5LsX7bsMWCmqv4Q+Bbwj30PKklamy738G8E5qvqXFW9BDwIHBpdUFUPV9ULw8NTwHS/Y0qS1qpL8HcB50eOF4bnLucO4LsrXZDkaJK5JHOLi4vdp5QkrVmvT9omuR2YAT630uVVdbyqZqpqZmpqqs+bliSNsaXDmmeA3SPH08NzvyHJ+4FPAu+rqhf7GU+S1Jcu9/BPA/uS7E1yNXAYmB1dkOQ9wJeAg1X1bP9jSpLWamzwq+oScBdwEngSeKiqziS5L8nB4bLPAW8GvpnkP5PMXubqJEkT0uUhHarqBHBi2bl7R75+f89zSZJ65jttJakRBl+SGmHwJakRBl+SGmHwJakRBl+SGmHwJakRBl+SGmHwJakRBl+SGmHwJakRBl+SGmHwJakRBl+SGmHwJakRBl+SGmHwJakRBl+SGmHwJakRBl+SGmHwJakRBl+SGmHwJakRBl+SGmHwJakRBl+SGmHwJakRBl+SGmHwJakRBl+SGmHwJakRBl+SGmHwJakRBl+SGmHwJakRnYKf5ECSp5LMJ7lnhct/K8k3hpf/KMme3ieVJK3J2OAnuQo4BtwK7AeOJNm/bNkdwHNV9XvAPwOf7XtQSdLadLmHfyMwX1Xnquol4EHg0LI1h4B/H379LeCWJOlvTEnSWm3psGYXcH7keAH448utqapLSZ4HdgC/HF2U5ChwdHj4YpInVjP0JrSTZXvVMPdiiXuxxL1Y8vur/cYuwe9NVR0HjgMkmauqmY28/SuVe7HEvVjiXixxL5YkmVvt93Z5SOcZYPfI8fTw3IprkmwBrgUurHYoSVL/ugT/NLAvyd4kVwOHgdlla2aBvxp+/ZfAf1RV9TemJGmtxj6kM3xM/i7gJHAVcH9VnUlyHzBXVbPAvwFfSzIP/IrBL4Vxjq9h7s3GvVjiXixxL5a4F0tWvRfxjrgktcF32kpSIwy+JDVi3YPvxzIs6bAXH09yNsnjSb6X5J2TmHMjjNuLkXUfSFJJNu1L8rrsRZIPDn82ziT5+kbPuFE6/B95R5KHkzw2/H9y2yTmXG9J7k/y7OXeq5SBLwz36fEkN3S64qpat38MnuT9L+B3gauBHwP7l635a+CLw68PA99Yz5km9a/jXvwZ8NvDrz/a8l4M120HHgFOATOTnnuCPxf7gMeA3xkev23Sc09wL44DHx1+vR94etJzr9Ne/ClwA/DEZS6/DfguEOAm4Eddrne97+H7sQxLxu5FVT1cVS8MD08xeM/DZtTl5wLgMww+l+niRg63wbrsxZ3Asap6DqCqnt3gGTdKl70o4C3Dr68Ffr6B822YqnqEwSseL+cQ8NUaOAW8Ncnbx13vegd/pY9l2HW5NVV1CXjlYxk2my57MeoOBr/BN6OxezH8E3V3VX1nIwebgC4/F9cB1yX5QZJTSQ5s2HQbq8tefBq4PckCcAL42MaMdsV5vT0BNvijFdRNktuBGeB9k55lEpK8Cfg88OEJj3Kl2MLgYZ2bGfzV90iSP6iq/5nkUBNyBPhKVf1Tkj9h8P6f66vq/yY92BvBet/D92MZlnTZC5K8H/gkcLCqXtyg2TbauL3YDlwPfD/J0wweo5zdpE/cdvm5WABmq+rlqvop8BMGvwA2my57cQfwEEBV/RDYxuCD1VrTqSfLrXfw/ViGJWP3Isl7gC8xiP1mfZwWxuxFVT1fVTurak9V7WHwfMbBqlr1h0Zdwbr8H/k2g3v3JNnJ4CGecxs440bpshc/A24BSPJuBsFf3NAprwyzwIeGr9a5CXi+qn4x7pvW9SGdWr+PZXjD6bgXnwPeDHxz+Lz1z6rq4MSGXicd96IJHffiJPAXSc4C/wt8oqo23V/BHffibuDLSf6OwRO4H96MdxCTPMDgl/zO4fMVnwK2AlTVFxk8f3EbMA+8AHyk0/Vuwr2SJK3Ad9pKUiMMviQ1wuBLUiMMviQ1wuBLUiMMviQ1wuBLUiP+H2qgkGiKkyLiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#plt.plot(train_acc[200:], label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-bd31bee9d1a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Save the model and plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMODEL_STORE_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'conv_net_model.ckpt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the model and plot\n",
    "torch.save(model.state_dict(), MODEL_STORE_PATH + 'conv_net_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
